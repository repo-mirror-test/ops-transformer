/**
 * Copyright (c) 2025 Huawei Technologies Co., Ltd.
 * This program is free software, you can redistribute it and/or modify it under the terms and conditions of
 * CANN Open Software License Agreement Version 2.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 */
#include <vector>
#include <array>
#include "gtest/gtest.h"
#include "../../../op_api/aclnn_flash_attention_score_grad.h"
#include "op_api_ut_common/tensor_desc.h"
#include "op_api_ut_common/scalar_desc.h"
#include "op_api_ut_common/op_api_ut.h"
#include "opdev/platform.h"

using namespace std;
using namespace op;

class flash_attention_score_grad_v3_opapi_ut : public testing::Test {
protected:
    static void SetUpTestCase()
    {
        cout << "flash_attention_score_grad_v3_opapi_ut SetUp" << endl;
    }

    static void TearDownTestCase()
    {
        cout << "flash_attention_score_grad_v3_opapi_ut TearDown" << endl;
    }
};

TEST_F(flash_attention_score_grad_v3_opapi_ut, flash_attention_score_grad_aclnn_1) {
    auto tensorQ = TensorDesc({256, 1, 192}, ACL_FLOAT, ACL_FORMAT_ND)
        .ValueRange(-1, 1);
    auto tensorK = TensorDesc({256, 1, 192}, ACL_FLOAT, ACL_FORMAT_ND)
        .ValueRange(-1, 1);
    auto tensorV = TensorDesc({256, 1, 192}, ACL_FLOAT, ACL_FORMAT_ND)
        .ValueRange(-1, 1);
    auto tensorDx = TensorDesc({256, 1, 192}, ACL_FLOAT, ACL_FORMAT_ND)
        .ValueRange(-1, 1);
    auto tensorAttenMask = TensorDesc({256, 256}, ACL_UINT8, ACL_FORMAT_ND)
        .Value(vector<uint8_t>{0});
        
    auto tensorSoftmaxMax =
        TensorDesc({1, 1, 256, 8}, ACL_FLOAT, ACL_FORMAT_ND).Value(vector<float>(1 * 1 * 256 * 8, 3.0f));
    auto tensorSoftmaxSum =
        TensorDesc({1, 1, 256, 8}, ACL_FLOAT, ACL_FORMAT_ND).Value(vector<float>(1 * 1 * 256 * 8, 3.0f));
    auto tensorAttentionIn = TensorDesc({256, 1, 192}, ACL_FLOAT, ACL_FORMAT_ND).ValueRange(-1, 1);

    const double scaleValue = 1.0 / sqrt(128);
    const double keepProb = 1.0;
    const int64_t preTokens = 65536;
    const int64_t nextTokens = 65536;
    const int64_t headNum = 1;
    char layout[] = "SBH";
    const int64_t innerPrecise = 0;
    const int64_t sparseMod = 0;
    const int64_t outDtype = 1;
    const int64_t pseType = 1;
    const int64_t seed = 0;
    const int64_t offset = 0;

    auto tensorDQDesc = TensorDesc({256, 1, 192}, ACL_FLOAT, ACL_FORMAT_ND);
    auto tensorDKDesc = TensorDesc({256, 1, 192}, ACL_FLOAT, ACL_FORMAT_ND);
    auto tensorDVDesc = TensorDesc({256, 1, 192}, ACL_FLOAT, ACL_FORMAT_ND);
    auto tensorDPseDesc = TensorDesc({}, ACL_FLOAT, ACL_FORMAT_ND);
    auto tensorDQROPEDesc = TensorDesc({}, ACL_FLOAT, ACL_FORMAT_ND);
    auto tensorDKROPEDesc = TensorDesc({}, ACL_FLOAT, ACL_FORMAT_ND);

    auto ut = OP_API_UT(
        aclnnFlashAttentionScoreGradV3,
        INPUT(
            tensorQ,
            tensorK,
            tensorV,
            tensorDx,
            nullptr,  // pse
            nullptr,  // dropmask
            nullptr,  // psepaddingmask
            tensorAttenMask,
            tensorSoftmaxMax,
            tensorSoftmaxSum,
            nullptr,  // softmaxin
            tensorAttentionIn,
            nullptr,  // sink
            nullptr,  // Prefix
            nullptr,  // QStartIdx
            nullptr,  // KVStartIdx
            scaleValue,
            keepProb,
            preTokens,
            nextTokens,
            headNum,
            layout,
            innerPrecise,
            sparseMod,
            pseType
        ),
        OUTPUT(
            tensorDQDesc,
            tensorDKDesc,
            tensorDVDesc,
            tensorDPseDesc,
            nullptr
        )
    );

    uint64_t workspaceSize = 0;
    aclnnStatus aclRet = ut.TestGetWorkspaceSize(&workspaceSize);
    EXPECT_EQ(aclRet, ACL_SUCCESS);
}