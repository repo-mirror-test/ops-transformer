/**
 * Copyright (c) 2025 Huawei Technologies Co., Ltd.
 * This program is free software, you can redistribute it and/or modify it under the terms and conditions of
 * CANN Open Software License Agreement Version 2.0 (the "License").
 * Please refer to the License for details. You may not use this file except in compliance with the License.
 * THIS SOFTWARE IS PROVIDED ON AN "AS IS" BASIS, WITHOUT WARRANTIES OF ANY KIND, EITHER EXPRESS OR IMPLIED,
 * INCLUDING BUT NOT LIMITED TO NON-INFRINGEMENT, MERCHANTABILITY, OR FITNESS FOR A PARTICULAR PURPOSE.
 * See LICENSE in the root of the software repository for the full text of the License.
 */
#include <gtest/gtest.h>
#include <iostream>
#include "infer_shape_context_faker.h"
#include "infer_datatype_context_faker.h"
#include "infer_shape_case_executor.h"
#include "base/registry/op_impl_space_registry_v2.h"

class FlashAttentionScoreGradProto : public testing::Test {
protected:
    static void SetUpTestCase()
    {
        std::cout << "FlashAttentionScoreGradProto SetUp" << std::endl;
    }

    static void TearDownTestCase()
    {
        std::cout << "FlashAttentionScoreGradProto TearDown" << std::endl;
    }
};

TEST_F(FlashAttentionScoreGradProto, flash_attention_score_grad_infershape_0)
{
    gert::InfershapeContextPara infershapeContextPara(
        "FlashAttentionScoreGrad",
        // 输入Tensor
        {
            // q
            {{{256, 1, 128}, {256, 1, 128}}, ge::DT_FLOAT, ge::FORMAT_ND},
            // k: S2=256, B=1, H2=128
            {{{256, 1, 128}, {256, 1, 128}}, ge::DT_FLOAT, ge::FORMAT_ND},
            // v: S2=256, B=1, H2=128
            {{{256, 1, 128}, {256, 1, 128}}, ge::DT_FLOAT, ge::FORMAT_ND},
            // dy
            {{{256, 1, 128}, {256, 1, 128}}, ge::DT_FLOAT, ge::FORMAT_ND},
            // pse_shift
            {{{}, {}}, ge::DT_FLOAT, ge::FORMAT_ND},
            // drop_mask
            {{{}, {}}, ge::DT_FLOAT, ge::FORMAT_ND},
            // padding_mask
            {{{}, {}}, ge::DT_INT32, ge::FORMAT_ND},
            // atten_mask: S1=256, S2=256
            {{{256, 256}, {256, 256}}, ge::DT_UINT8, ge::FORMAT_ND},
            // softmax_max
            {{{1,1,256,8}, {1,1,256,8}}, ge::DT_FLOAT, ge::FORMAT_ND},
            // softmax_sum
            {{{1,1,256,8}, {1,1,256,8}}, ge::DT_FLOAT, ge::FORMAT_ND},
            // softmax_in
            {{{}, {}}, ge::DT_FLOAT, ge::FORMAT_ND},
            // attention_in
            {{{256,1,128}, {256,1,128}}, ge::DT_FLOAT, ge::FORMAT_ND},
            // prefix
            {{{}, {}}, ge::DT_INT64, ge::FORMAT_ND},
            // actual_seq_qlen
            {{{}, {}}, ge::DT_INT64, ge::FORMAT_ND},
            // actual_seq_kvlen
            {{{}, {}}, ge::DT_INT64, ge::FORMAT_ND},
            // q_start_idx
            {{{}, {}}, ge::DT_INT64, ge::FORMAT_ND},
            // kv_start_idx
            {{{}, {}}, ge::DT_INT64, ge::FORMAT_ND},
            // dScaleQ
            {{{}, {}}, ge::DT_FLOAT, ge::FORMAT_ND},
            // dScaleK
            {{{}, {}}, ge::DT_FLOAT, ge::FORMAT_ND},
            // dScaleV
            {{{}, {}}, ge::DT_FLOAT, ge::FORMAT_ND},
            // dScaledy
            {{{}, {}}, ge::DT_FLOAT, ge::FORMAT_ND},
            // dScaleo
            {{{}, {}}, ge::DT_FLOAT, ge::FORMAT_ND},
            // queryRope
            {{{}, {}}, ge::DT_FLOAT, ge::FORMAT_ND},
            // keyRope
            {{{}, {}}, ge::DT_FLOAT, ge::FORMAT_ND},
        },
        {// 输出Tensor
        // dq
        {{{}, {}}, ge::DT_FLOAT, ge::FORMAT_ND},
        // dk
        {{{}, {}}, ge::DT_FLOAT, ge::FORMAT_ND},
        // dv
        {{{}, {}}, ge::DT_FLOAT, ge::FORMAT_ND},
        // dpse
        {{{}, {}}, ge::DT_FLOAT, ge::FORMAT_ND},
        // dq_rope
        {{{}, {}}, ge::DT_FLOAT, ge::FORMAT_ND},
        // dk_rope
        {{{}, {}}, ge::DT_FLOAT, ge::FORMAT_ND},
        },
        {// 属性
        {"scale_value", Ops::Transformer::AnyValue::CreateFrom<float>(0.088388f)},
        {"keep_prob", Ops::Transformer::AnyValue::CreateFrom<float>(1.0f)},
        {"pre_tockens", Ops::Transformer::AnyValue::CreateFrom<int64_t>(65536)},
        {"next_tockens", Ops::Transformer::AnyValue::CreateFrom<int64_t>(65536)},
        {"head_num", Ops::Transformer::AnyValue::CreateFrom<int64_t>(1)},
        {"input_layout", Ops::Transformer::AnyValue::CreateFrom<std::string>("SBH")},
        {"inner_precise", Ops::Transformer::AnyValue::CreateFrom<int64_t>(0)},
        {"sparse_mode", Ops::Transformer::AnyValue::CreateFrom<int64_t>(0)},
        {"pse_type", Ops::Transformer::AnyValue::CreateFrom<int64_t>(1)},
        {"seed", Ops::Transformer::AnyValue::CreateFrom<int64_t>(0)},
        {"offset", Ops::Transformer::AnyValue::CreateFrom<int64_t>(0)},
        {"out_dtype", Ops::Transformer::AnyValue::CreateFrom<int64_t>(0)},
        {"softmax_in_layout", Ops::Transformer::AnyValue::CreateFrom<std::string>("same_as_input")}});

    std::vector<std::vector<int64_t>> expectOutputShape = {
        {256, 1, 128},  
        {256, 1, 128},  
        {256, 1, 128},    
        {},        
        {},        
        {},        
    };
    ExecuteTestCase(infershapeContextPara, ge::GRAPH_SUCCESS, expectOutputShape);
}