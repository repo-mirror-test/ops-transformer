# aclnnFlashAttentionScoreGrad

[ğŸ“„ æŸ¥çœ‹æºç ](https://gitcode.com/cann/ops-transformer/tree/master/attention/flash_attention_score_grad)

## äº§å“æ”¯æŒæƒ…å†µ
|äº§å“      | æ˜¯å¦æ”¯æŒ |
|:----------------------------|:-----------:|
|<term>æ˜‡è…¾ 950PR/950DT AIå¤„ç†å™¨</term>|      Ã—     |
|<term>Atlas A3 è®­ç»ƒç³»åˆ—äº§å“/Atlas A3 æ¨ç†ç³»åˆ—äº§å“</term>|      âˆš     |
|<term>Atlas A2 è®­ç»ƒç³»åˆ—äº§å“</term>|      âˆš     |
|<term>Atlas 800I A2 æ¨ç†äº§å“</term>|      Ã—     |
|<term>A200I A2 Box å¼‚æ„ç»„ä»¶</term>|      Ã—     |


## åŠŸèƒ½è¯´æ˜

-   æ¥å£åŠŸèƒ½ï¼šè®­ç»ƒåœºæ™¯ä¸‹è®¡ç®—æ³¨æ„åŠ›çš„åå‘è¾“å‡ºï¼Œå³[aclnnFlashAttentionScore](../../flash_attention_score/docs/aclnnFlashAttentionScore.md)çš„åå‘è®¡ç®—ã€‚
-   è®¡ç®—å…¬å¼ï¼š

    å·²çŸ¥æ³¨æ„åŠ›çš„æ­£å‘è®¡ç®—å…¬å¼ä¸ºï¼š

    $$
    Y=Dropout(Softmax(Mask(\frac{QK^T+pse}{\sqrt{d}}),atten\_mask),keep\_prob)V
    $$

    ä¸ºæ–¹ä¾¿è¡¨è¾¾ï¼Œä»¥å˜é‡$S$å’Œ$P$è¡¨ç¤ºè®¡ç®—å…¬å¼ï¼š

    $$
    S=Mask(\frac{QK^T+pse}{\sqrt{d}},atten\_mask)
    $$

    $$
    P=Dropout(Softmax(S),keep\_prob)
    $$

    $$
    Y=PV
    $$

    åˆ™æ³¨æ„åŠ›çš„åå‘è®¡ç®—å…¬å¼ä¸ºï¼š

    $$
    dV=P^TdY
    $$

    $$
    dQ=\frac{((dS)*K)}{\sqrt{d}}
    $$

    $$
    dK=\frac{((dS)^T*Q)}{\sqrt{d}}
    $$


## å‡½æ•°åŸå‹
æ¯ä¸ªç®—å­åˆ†ä¸º[ä¸¤æ®µå¼æ¥å£](../../../docs/zh/context/ä¸¤æ®µå¼æ¥å£.md)ï¼Œå¿…é¡»å…ˆè°ƒç”¨â€œaclnnFlashAttentionScoreGradGetWorkspaceSizeâ€æ¥å£è·å–è®¡ç®—æ‰€éœ€workspaceå¤§å°ä»¥åŠåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹çš„æ‰§è¡Œå™¨ï¼Œå†è°ƒç”¨â€œaclnnFlashAttentionScoreGradâ€æ¥å£æ‰§è¡Œè®¡ç®—ã€‚

```c++
aclnnStatus aclnnFlashAttentionScoreGradGetWorkspaceSize(
  const aclTensor   *query, 
  const aclTensor   *keyIn, 
  const aclTensor   *value, 
  const aclTensor   *dy, 
  const aclTensor   *pseShiftOptional, 
  const aclTensor   *dropMaskOptional, 
  const aclTensor   *paddingMaskOptional, 
  const aclTensor   *attenMaskOptional, 
  const aclTensor   *softmaxMaxOptional, 
  const aclTensor   *softmaxSumOptional, 
  const aclTensor   *softmaxInOptional, 
  const aclTensor   *attentionInOptional, 
  const aclIntArray *prefixOptional, 
  double             scaleValue, 
  double             keepProb, 
  int64_t            preTokens, 
  int64_t            nextTokens, 
  int64_t            headNum, 
  char              *inputLayout, 
  int64_t            innerPrecise, 
  int64_t            sparseMode, 
  const aclTensor   *dqOut, 
  const aclTensor   *dkOut, 
  const aclTensor   *dvOut, 
  const aclTensor   *dpseOut, 
  uint64_t          *workspaceSize, 
  aclOpExecutor    **executor)
```
```c++
aclnnStatus aclnnFlashAttentionScoreGrad(
  void             *workspace, 
  uint64_t          workspaceSize, 
  aclOpExecutor    *executor, 
  const aclrtStream stream)
```


## aclnnFlashAttentionScoreGradGetWorkspaceSize

- **å‚æ•°è¯´æ˜ï¼š**
    <table style="undefined;table-layout: fixed; width: 1529px"><colgroup>
      <col style="width: 198px">
      <col style="width: 120px">
      <col style="width: 289px">
      <col style="width: 302px">
      <col style="width: 238px">
      <col style="width: 106px">
      <col style="width: 130px">
      <col style="width: 146px">
      </colgroup>
      <thead>
        <tr>
          <th>å‚æ•°å</th>
          <th>è¾“å…¥/è¾“å‡º</th>
          <th>æè¿°</th>
          <th>ä½¿ç”¨è¯´æ˜</th>
          <th>æ•°æ®ç±»å‹</th>
          <th>æ•°æ®æ ¼å¼</th>
          <th>ç»´åº¦(shape)</th>
          <th>éè¿ç»­Tensor</th>
        </tr></thead>
      <tbody>
        <tr>
          <td>query</td>
          <td>è¾“å…¥</td>
          <td>å…¬å¼ä¸­çš„Qã€‚</td>
          <td>æ•°æ®ç±»å‹ä¸keyIn/valueçš„æ•°æ®ç±»å‹ä¸€è‡´ã€‚</td>
          <td>FLOAT16ã€BFLOAT16ã€FLOAT32</td>
          <td>ND</td>
          <td>[BNSD]ã€[BSND]ã€[BSH]ã€[SBH]</td>
          <td>âˆš</td>
        </tr>
        <tr>
          <td>keyIn</td>
          <td>è¾“å…¥</td>
          <td>å…¬å¼ä¸­çš„Kã€‚</td>
          <td>æ•°æ®ç±»å‹ä¸query/valueçš„æ•°æ®ç±»å‹ä¸€è‡´ã€‚</td>
          <td>FLOAT16ã€BFLOAT16ã€FLOAT32</td>
          <td>ND</td>
          <td>[BNSD]ã€[BSND]ã€[BSH]ã€[SBH]</td>
          <td>âˆš</td>
        </tr>
        <tr>
          <td>value</td>
          <td>è¾“å…¥</td>
          <td>å…¬å¼ä¸­çš„Vã€‚</td>
          <td>æ•°æ®ç±»å‹ä¸query/keyInçš„æ•°æ®ç±»å‹ä¸€è‡´ã€‚</td>
          <td>FLOAT16ã€BFLOAT16ã€FLOAT32</td>
          <td>ND</td>
          <td>[BNSD]ã€[BSND]ã€[BSH]ã€[SBH]</td>
          <td>âˆš</td>
        </tr>
        <tr>
          <td>dy</td>
          <td>è¾“å…¥</td>
          <td>å…¬å¼ä¸­çš„è¾“å…¥dYã€‚</td>
          <td>-</td>
          <td>FLOAT16ã€BFLOAT16ã€FLOAT32</td>
          <td>ND</td>
          <td>[BNSD]ã€[BSND]ã€[BSH]ã€[SBH]</td>
          <td>âˆš</td>
        </tr>
        <tr>
          <td>pseShiftOptional</td>
          <td>å¯é€‰è¾“å…¥</td>
          <td>å…¬å¼ä¸­çš„pseã€‚</td>
          <td>æ•°æ®ç±»å‹ä¸queryçš„æ•°æ®ç±»å‹ä¸€è‡´ã€‚</td>
          <td>FLOAT16ã€BFLOAT16ã€FLOAT32</td>
          <td>ND</td>
          <td>[B,N,Sq,Skv]ã€[B,N,1,Skv]ã€[1,N,Sq,Skv]ã€[B,N,1024,Skv]ã€[1,N,1024,Skv]</td>
          <td>âˆš</td>
        </tr>
        <tr>
          <td>dropMaskOptional</td>
          <td>è¾“å…¥</td>
          <td>å…¬å¼ä¸­çš„Dropoutã€‚</td>
          <td>-</td>
          <td>UINT8</td>
          <td>ND</td>
          <td>0ã€1</td>
          <td>âˆš</td>
        </tr>
        <tr>
          <td>attenMaskOptional</td>
          <td>è¾“å…¥</td>
          <td>å…¬å¼ä¸­çš„atten_maskã€‚</td>
          <td>å–å€¼ä¸º1ä»£è¡¨è¯¥ä½ä¸å‚ä¸è®¡ç®—ï¼Œä¸º0ä»£è¡¨è¯¥ä½å‚ä¸è®¡ç®—ã€‚</td>
          <td>BOOLã€UINT8</td>
          <td>ND</td>
          <td>[B,N,Sq,Skv]ã€[B,1,Sq,Skv]ã€[1,1,Sq,Skv]ã€[Sq,Skv] </td>
          <td>âˆš</td>
        </tr>
        <tr>
          <td>softmaxMaxOptional</td>
          <td>è¾“å…¥</td>
          <td>æ³¨æ„åŠ›æ­£å‘è®¡ç®—çš„ä¸­é—´è¾“å‡ºã€‚</td>
          <td>-</td>
          <td>FLOAT</td>
          <td>ND</td>
          <td>[B,N,Sq,8]</td>
          <td>âˆš</td>
        </tr>
        <tr>
          <td>softmaxSumOptional</td>
          <td>è¾“å…¥</td>
          <td>æ³¨æ„åŠ›æ­£å‘è®¡ç®—çš„ä¸­é—´è¾“å‡ºã€‚</td>
          <td>-</td>
          <td>FLOAT</td>
          <td>ND</td>
          <td>[B,N,Sq,8]</td>
          <td>âˆš</td>
        </tr>
        <tr>
          <td>attentionInOptional</td>
          <td>è¾“å…¥</td>
          <td>æ³¨æ„åŠ›æ­£å‘è®¡ç®—çš„æœ€ç»ˆè¾“å‡ºã€‚</td>
          <td>æ•°æ®ç±»å‹å’Œshapeç±»å‹ä¸queryä¿æŒä¸€è‡´ã€‚</td>
          <td>FLOAT16ã€BFLOAT16ã€FLOAT32</td>
          <td>ND</td>
          <td>[BNSD]ã€[BSND]ã€[BSH]ã€[SBH]</td>
          <td>âˆš</td>
        </tr>
        <tr>
          <td>prefixOptional</td>
          <td>è¾“å…¥</td>
          <td>ä»£è¡¨prefixç¨€ç–è®¡ç®—åœºæ™¯æ¯ä¸ªBatchçš„Nå€¼ã€‚</td>
          <td>-</td>
          <td>INT64</td>
          <td>ND</td>
          <td>0ã€1</td>
          <td>-</td>
        </tr>
        <tr>
          <td>dqOut</td>
          <td>è¾“å‡º</td>
          <td>å…¬å¼ä¸­çš„dQï¼Œè¡¨ç¤ºqueryçš„æ¢¯åº¦ã€‚</td>
          <td>-</td>
          <td>FLOAT16ã€BFLOAT16ã€FLOAT32</td>
          <td>ND</td>
          <td>[BNSD]ã€[BSND]ã€[BSH]ã€[SBH]</td>
          <td>âˆš</td>
        </tr>
        <tr>
          <td>dkOut</td>
          <td>è¾“å‡º</td>
          <td>å…¬å¼ä¸­çš„dKï¼Œè¡¨ç¤ºkeyInçš„æ¢¯åº¦ã€‚</td>
          <td>-</td>
          <td>FLOAT16ã€BFLOAT16ã€FLOAT32</td>
          <td>ND</td>
          <td>[BNSD]ã€[BSND]ã€[BSH]ã€[SBH]</td>
          <td>âˆš</td>
        </tr>
        <tr>
          <td>dvOut</td>
          <td>è¾“å‡º</td>
          <td>å…¬å¼ä¸­çš„dVï¼Œè¡¨ç¤ºvalueçš„æ¢¯åº¦ã€‚</td>
          <td>-</td>
          <td>FLOAT16ã€BFLOAT16ã€FLOAT32</td>
          <td>ND</td>
          <td>[BNSD]ã€[BSND]ã€[BSH]ã€[SBH]</td>
          <td>âˆš</td>
        </tr>
        <tr>
          <td>dpseOut</td>
          <td>è¾“å‡º</td>
          <td>d(pse)æ¢¯åº¦ã€‚</td>
          <td>æš‚æœªä½¿ç”¨ã€‚</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
        </tr>
        <tr>
          <td>scaleValue</td>
          <td>è¾“å…¥</td>
          <td>å…¬å¼ä¸­çš„scaleï¼Œä»£è¡¨ç¼©æ”¾ç³»æ•°ã€‚</td>
          <td>-</td>
          <td>DOUBLE</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
        </tr>
        <tr>
          <td>keepProb</td>
          <td>è¾“å…¥</td>
          <td>ä»£è¡¨dropMaskOptionalä¸­1çš„æ¯”ä¾‹ã€‚</td>
          <td>-</td>
          <td>DOUBLE</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
        </tr>
        <tr>
          <td>preTokens</td>
          <td>è¾“å…¥</td>
          <td>ç”¨äºç¨€ç–è®¡ç®— ï¼Œè¡¨ç¤ºslides windowçš„å·¦è¾¹ç•Œã€‚</td>
          <td>-</td>
          <td>INT64</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
        </tr>
        <tr>
          <td>nextTokens</td>
          <td>è¾“å…¥</td>
          <td>ç”¨äºç¨€ç–è®¡ç®—ï¼Œè¡¨ç¤ºslides windowçš„å³è¾¹ç•Œã€‚</td>
          <td>-</td>
          <td>INT64</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
        </tr>
        <tr>
          <td>headNum</td>
          <td>è¾“å…¥</td>
          <td>ä»£è¡¨å•å¡çš„headä¸ªæ•°ï¼Œå³è¾“å…¥queryçš„Nè½´é•¿åº¦ã€‚</td>
          <td>-</td>
          <td>INT64</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
        </tr>
        <tr>
          <td>inputLayout</td>
          <td>è¾“å…¥</td>
          <td>ä»£è¡¨è¾“å…¥queryã€keyã€valueçš„æ•°æ®æ’å¸ƒæ ¼å¼ã€‚</td>
          <td>æ”¯æŒBSHã€SBHã€BSNDã€BNSDã€‚</td>
          <td>String</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
        </tr>
        <tr>
          <td>sparseMode</td>
          <td>è¾“å…¥</td>
          <td>è¡¨ç¤ºsparseçš„æ¨¡å¼ã€‚</td>
          <td>æ”¯æŒé…ç½®å€¼ä¸º0ã€1ã€2ã€3ã€4ã€5ã€6ã€‚</td>
          <td>INT64</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
        </tr>
        <tr>
          <td>workspaceSize</td>
          <td>è¾“å‡º</td>
          <td>è¿”å›éœ€è¦åœ¨Deviceä¾§ç”³è¯·çš„workspaceå¤§å°ã€‚</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
        </tr>
        <tr>
          <td>executor</td>
          <td>è¾“å‡º</td>
          <td>è¿”å›opæ‰§è¡Œå™¨ï¼ŒåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹ã€‚</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
          <td>-</td>
        </tr>
      </tbody>
    </table>

- **è¿”å›å€¼ï¼š**

  è¿”å›aclnnStatusçŠ¶æ€ç ï¼Œå…·ä½“å‚è§[aclnnè¿”å›ç ](../../../docs/zh/context/aclnnè¿”å›ç .md)ã€‚

  ç¬¬ä¸€æ®µæ¥å£å®Œæˆå…¥å‚æ ¡éªŒï¼Œå‡ºç°ä»¥ä¸‹åœºæ™¯æ—¶æŠ¥é”™ï¼š
  <table style="undefined;table-layout: fixed;width: 1202px"><colgroup>
  <col style="width: 262px">
  <col style="width: 121px">
  <col style="width: 819px">
  </colgroup>
  <thead>
    <tr>
      <th>è¿”å›ç </th>
      <th>é”™è¯¯ç </th>
      <th>æè¿°</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>ACLNN_ERR_PARAM_NULLPTR</td>
      <td>161001</td>
      <td>ä¼ å…¥å‚æ•°æ˜¯å¿…é€‰è¾“å…¥ï¼Œè¾“å‡ºæˆ–è€…å¿…é€‰å±æ€§ï¼Œä¸”æ˜¯ç©ºæŒ‡é’ˆã€‚</td>
    </tr>
    <tr>
      <td rowspan="2">ACLNN_ERR_PARAM_INVALID</td>
      <td rowspan="2">161002</td>
      <td>queryã€keyInã€valueã€dyã€pseShiftOptionalã€dropMaskOptionalã€paddingMaskOptionalã€attenMaskOptionalã€softmaxMaxOptionalã€softmaxSumOptionalã€softmaxInOptionalã€attentionInOptionalã€dqOutã€dkOutã€dvOutçš„æ•°æ®ç±»å‹ä¸åœ¨æ”¯æŒçš„èŒƒå›´å†…ã€‚</td>
    </tr>
    <tr>
      <td>queryã€keyInã€valueã€dyã€pseShiftOptionalã€dropMaskOptionalã€paddingMaskOptionalã€attenMaskOptionalã€softmaxMaxOptionalã€softmaxSumOptionalã€softmaxInOptionalã€attentionInOptionalã€dqOutã€dkOutã€dvOutçš„æ•°æ®æ ¼å¼ä¸åœ¨æ”¯æŒçš„èŒƒå›´å†…ã€‚</td>
    </tr>
  </tbody>
  </table>


## aclnnFlashAttentionScoreGrad

- **å‚æ•°è¯´æ˜ï¼š**
  <table style="undefined;table-layout: fixed; width: 1154px"><colgroup>
  <col style="width: 153px">
  <col style="width: 121px">
  <col style="width: 880px">
  </colgroup>
  <thead>
    <tr>
      <th>å‚æ•°å</th>
      <th>è¾“å…¥/è¾“å‡º</th>
      <th>æè¿°</th>
    </tr></thead>
  <tbody>
    <tr>
      <td>workspace</td>
      <td>è¾“å…¥</td>
      <td>åœ¨Deviceä¾§ç”³è¯·çš„workspaceå†…å­˜åœ°å€ã€‚</td>
    </tr>
    <tr>
      <td>workspaceSize</td>
      <td>è¾“å…¥</td>
      <td>åœ¨Deviceä¾§ç”³è¯·çš„workspaceå¤§å°ï¼Œç”±ç¬¬ä¸€æ®µæ¥å£aclnnFlashAttentionScoreGradGetWorkspaceSizeè·å–ã€‚</td>
    </tr>
    <tr>
      <td>executor</td>
      <td>è¾“å…¥</td>
      <td>opæ‰§è¡Œå™¨ï¼ŒåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹ã€‚</td>
    </tr>
    <tr>
      <td>stream</td>
      <td>è¾“å…¥</td>
      <td>æŒ‡å®šæ‰§è¡Œä»»åŠ¡çš„Streamã€‚</td>
    </tr>
  </tbody>
  </table>

- **è¿”å›å€¼ï¼š**

    è¿”å›aclnnStatusçŠ¶æ€ç ï¼Œå…·ä½“å‚è§[aclnnè¿”å›ç ](../../../docs/zh/context/aclnnè¿”å›ç .md)ã€‚

## çº¦æŸè¯´æ˜

- ç¡®å®šæ€§è®¡ç®—ï¼š
  - aclnnFlashAttentionScoreGradé»˜è®¤éç¡®å®šæ€§å®ç°ï¼Œæ”¯æŒé€šè¿‡aclrtCtxSetSysParamOptå¼€å¯ç¡®å®šæ€§ã€‚
- è¯¥æ¥å£ä¸PyTorché…åˆä½¿ç”¨æ—¶ï¼Œéœ€è¦ä¿è¯CANNç›¸å…³åŒ…ä¸PyTorchç›¸å…³åŒ…çš„ç‰ˆæœ¬åŒ¹é…ã€‚
- è¾“å…¥queryã€keyã€valueã€dyçš„Bï¼šbatchsizeå¿…é¡»ç›¸ç­‰ã€‚
- è¾“å…¥queryã€keyã€valueçš„Dï¼šHead-Dimå¿…é¡»æ»¡è¶³(qD == kD && kD >= vD)ã€‚
- è¾“å…¥queryã€keyã€valueã€dyçš„inputLayoutå¿…é¡»ä¸€è‡´ã€‚
- è¾“å…¥queryã€keyã€valueã€pseShiftOptionalçš„æ•°æ®ç±»å‹å¿…é¡»ä¸€è‡´ã€‚
- è¾“å…¥key/valueçš„shapeé™¤Då¤–å¿…é¡»ä¸€è‡´ï¼Œåœ¨query/key/valueçš„Då¤§å°ç›¸åŒçš„æƒ…å†µä¸‹ï¼Œquery/dyçš„shapeå¿…é¡»ä¸€è‡´ã€‚
- æ”¯æŒè¾“å…¥query/dyçš„Nå’Œkey/valueçš„Nä¸ç›¸ç­‰ï¼Œä½†å¿…é¡»æˆæ¯”ä¾‹å…³ç³»ï¼Œå³Nq/Nkvå¿…é¡»æ˜¯é0æ•´æ•°ï¼ŒNqå–å€¼èŒƒå›´1~256ã€‚
-   å…³äºæ•°æ®shapeçš„çº¦æŸï¼Œä»¥inputLayoutçš„BSNDã€BNSDä¸ºä¾‹ï¼ˆBSHã€SBHä¸‹H=N\*Dï¼‰ï¼Œå…¶ä¸­ï¼š
    - Bï¼šå–å€¼èŒƒå›´ä¸º1\~2Mã€‚å¸¦prefixOptionalçš„æ—¶å€™Bæœ€å¤§æ”¯æŒ2Kã€‚
    - Nï¼šå–å€¼èŒƒå›´ä¸º1\~256ã€‚
    - Sï¼šå–å€¼èŒƒå›´ä¸º1\~1Mã€‚
    - Dï¼šå–å€¼èŒƒå›´ä¸º1\~768ã€‚
- queryã€keyInã€valueæ•°æ®æ’å¸ƒæ ¼å¼æ”¯æŒä»å¤šç§ç»´åº¦è§£è¯»ï¼Œå…¶ä¸­Bï¼ˆBatchï¼‰è¡¨ç¤ºè¾“å…¥æ ·æœ¬æ‰¹é‡å¤§å°ã€Sï¼ˆSeq-Lengthï¼‰è¡¨ç¤ºè¾“å…¥æ ·æœ¬åºåˆ—é•¿åº¦ã€Hï¼ˆHead-Sizeï¼‰è¡¨ç¤ºéšè—å±‚çš„å¤§å°ã€Nï¼ˆHead-Numï¼‰è¡¨ç¤ºå¤šå¤´æ•°ã€Dï¼ˆHead-Dimï¼‰è¡¨ç¤ºéšè—å±‚æœ€å°çš„å•å…ƒå°ºå¯¸ï¼Œä¸”æ»¡è¶³D=H/Nã€‚
- realShiftOptionalï¼šå¦‚æœSqå¤§äº1024çš„æ¯ä¸ªbatchçš„Sqä¸Skvç­‰é•¿ä¸”æ˜¯sparseModeä¸º0ã€2ã€3çš„ä¸‹ä¸‰è§’æ©ç åœºæ™¯ï¼Œå¯ä½¿èƒ½alibiä½ç½®ç¼–ç å‹ç¼©ï¼Œæ­¤æ—¶åªéœ€è¦è¾“å…¥åŸå§‹PSEæœ€å1024è¡Œè¿›è¡Œå†…å­˜ä¼˜åŒ–ï¼Œå³alibi_compress = ori_pse[:, :, -1024:, :]ï¼Œå…·ä½“å¦‚ä¸‹ï¼š
  - å‚æ•°æ¯ä¸ªbatchä¸ç›¸åŒæ—¶ï¼Œshapeä¸ºBNHSkv(H=1024)ã€‚
  - æ¯ä¸ªbatchç›¸åŒæ—¶ï¼Œshapeä¸º1NHSkv(H=1024)ã€‚
  - å¦‚ä¸ä½¿ç”¨è¯¥å‚æ•°å¯ä¼ å…¥nullptrã€‚
- innerPrecise: å½“å‰0ã€1ä¸ºä¿ç•™é…ç½®å€¼ï¼Œ2ä¸ºä½¿èƒ½æ— æ•ˆè¡Œè®¡ç®—ï¼Œå…¶åŠŸèƒ½æ˜¯é¿å…åœ¨è®¡ç®—è¿‡ç¨‹ä¸­å­˜åœ¨æ•´è¡Œmaskè¿›è€Œå¯¼è‡´ç²¾åº¦æœ‰æŸå¤±ï¼Œä½†æ˜¯è¯¥é…ç½®ä¼šå¯¼è‡´æ€§èƒ½ä¸‹é™ã€‚ å¦‚æœç®—å­å¯åˆ¤æ–­å‡ºå­˜åœ¨æ— æ•ˆè¡Œåœºæ™¯ï¼Œä¼šè‡ªåŠ¨ä½¿èƒ½æ— æ•ˆè¡Œè®¡ç®—ï¼Œä¾‹å¦‚sparseModeä¸º3ï¼ŒSq > Skvåœºæ™¯ã€‚
- sparseModeçš„çº¦æŸå¦‚ä¸‹:
  - å½“æ‰€æœ‰çš„attenMaskOptionalçš„shapeå°äº2048ä¸”ç›¸åŒçš„æ—¶å€™ï¼Œå»ºè®®ä½¿ç”¨defaultæ¨¡å¼ï¼Œæ¥å‡å°‘å†…å­˜ä½¿ç”¨é‡ï¼›
  - é…ç½®ä¸º1ã€2ã€3ã€5æ—¶ï¼Œç”¨æˆ·é…ç½®çš„preTokensã€nextTokensä¸ä¼šç”Ÿæ•ˆï¼›
  - é…ç½®ä¸º0ã€4æ—¶ï¼Œé¡»ä¿è¯attenMaskOptionalä¸preTokensã€nextTokensçš„èŒƒå›´ä¸€è‡´ã€‚
  - ç”¨æˆ·ä¸ç‰¹æ„æŒ‡å®šæ—¶å»ºè®®ä¼ å…¥0ã€‚
  - sparseä¸åŒæ¨¡å¼çš„è¯¦ç»†è¯´æ˜è¯·å‚è§[sparseæ¨¡å¼è¯´æ˜](../../../docs/zh/context/sparse_modeå‚æ•°è¯´æ˜.md)ã€‚
-   éƒ¨åˆ†åœºæ™¯ä¸‹ï¼Œå¦‚æœè®¡ç®—é‡è¿‡å¤§å¯èƒ½ä¼šå¯¼è‡´ç®—å­æ‰§è¡Œè¶…æ—¶(aicore errorç±»å‹æŠ¥é”™ï¼ŒerrorSträ¸ºï¼štimeout or trap error)ï¼Œæ­¤æ—¶å»ºè®®åšè½´åˆ‡åˆ†å¤„ç†ï¼Œæ³¨ï¼šè¿™é‡Œçš„è®¡ç®—é‡ä¼šå—Bã€Sã€Nã€Dç­‰å‚æ•°çš„å½±å“ï¼Œå€¼è¶Šå¤§è®¡ç®—é‡è¶Šå¤§ã€‚
-   å…³äºsoftmaxMaxä¸softmaxSumå‚æ•°çš„çº¦æŸï¼šè¾“å…¥æ ¼å¼å›ºå®šä¸º\[B, N, S, 8\]ï¼›TNDçš„è¾“å…¥æ ¼å¼é™¤å¤–ï¼Œæ­¤æ—¶ä¸º\[T, N, 8\]ï¼Œæ³¨ï¼šT=B*Sã€‚
-   headNumçš„å–å€¼å¿…é¡»å’Œä¼ å…¥çš„Queryä¸­çš„Nå€¼ä¿æŒä¸€è‡´ã€‚
-   bandåœºæ™¯ï¼ŒpreTokenså’ŒnextTokensä¹‹é—´å¿…é¡»è¦æœ‰äº¤é›†ã€‚
-   pseShiftOptionalä¸­çš„Sqåœ¨å¤§äº1024åœºæ™¯ä¸‹ï¼Œä¸”æ­¤æ—¶shapeå–å€¼ä¸ºBNHSæˆ–1NHSæ—¶ï¼Œéœ€è¦æ»¡è¶³Sqå’ŒSkvç­‰é•¿ã€‚
-   prefixOptionalç¨€ç–è®¡ç®—åœºæ™¯ï¼Œå³sparseMode=5æˆ–è€…sparseMode=6ï¼Œå½“Sq > Skvæ—¶ï¼Œprefixçš„Nå€¼å–å€¼èŒƒå›´\[0, Skv\]ï¼Œå½“Sq <= Skvæ—¶ï¼Œprefixçš„Nå€¼å–å€¼èŒƒå›´\[Skv-Sq, Skv\]ã€‚


## è°ƒç”¨ç¤ºä¾‹

è°ƒç”¨ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼Œä»…ä¾›å‚è€ƒï¼Œå…·ä½“ç¼–è¯‘å’Œæ‰§è¡Œè¿‡ç¨‹è¯·å‚è€ƒ[ç¼–è¯‘ä¸è¿è¡Œæ ·ä¾‹](../../../docs/zh/context/ç¼–è¯‘ä¸è¿è¡Œæ ·ä¾‹.md)ã€‚

```c++
#include <iostream>
#include <vector>
#include "acl/acl.h"
#include "aclnnop/aclnn_flash_attention_score_grad.h"

#define CHECK_RET(cond, return_expr) \
  do {                               \
    if (!(cond)) {                   \
      return_expr;                   \
    }                                \
  } while (0)

#define LOG_PRINT(message, ...)     \
  do {                              \
    printf(message, ##__VA_ARGS__); \
  } while (0)

int64_t GetShapeSize(const std::vector<int64_t>& shape) {
  int64_t shapeSize = 1;
  for (auto i : shape) {
    shapeSize *= i;
  }
  return shapeSize;
}

void PrintOutResult(std::vector<int64_t> &shape, void** deviceAddr) {
  auto size = GetShapeSize(shape);
  std::vector<float> resultData(size, 0);
  auto ret = aclrtMemcpy(resultData.data(), resultData.size() * sizeof(resultData[0]),
                         *deviceAddr, size * sizeof(resultData[0]), ACL_MEMCPY_DEVICE_TO_HOST);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("copy result from device to host failed. ERROR: %d\n", ret); return);
  for (int64_t i = 0; i < size; i++) {
    LOG_PRINT("mean result[%ld] is: %f\n", i, resultData[i]);
  }
}

int Init(int32_t deviceId, aclrtContext* context, aclrtStream* stream) {
  // å›ºå®šå†™æ³•ï¼Œèµ„æºåˆå§‹åŒ–
  auto ret = aclInit(nullptr);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclInit failed. ERROR: %d\n", ret); return ret);
  ret = aclrtSetDevice(deviceId);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSetDevice failed. ERROR: %d\n", ret); return ret);
  ret = aclrtCreateContext(context, deviceId);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtCreateContext failed. ERROR: %d\n", ret); return ret);
  ret = aclrtSetCurrentContext(*context);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSetCurrentContext failed. ERROR: %d\n", ret); return ret);
  ret = aclrtCreateStream(stream);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtCreateStream failed. ERROR: %d\n", ret); return ret);
  return 0;
}

template <typename T>
int CreateAclTensor(const std::vector<T>& hostData, const std::vector<int64_t>& shape, void** deviceAddr,
                    aclDataType dataType, aclTensor** tensor) {
  auto size = GetShapeSize(shape) * sizeof(T);
  // è°ƒç”¨aclrtMallocç”³è¯·deviceä¾§å†…å­˜
  auto ret = aclrtMalloc(deviceAddr, size, ACL_MEM_MALLOC_HUGE_FIRST);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMalloc failed. ERROR: %d\n", ret); return ret);
  // è°ƒç”¨aclrtMemcpyå°†hostä¾§æ•°æ®æ‹·è´åˆ°deviceä¾§å†…å­˜ä¸Š
  ret = aclrtMemcpy(*deviceAddr, size, hostData.data(), size, ACL_MEMCPY_HOST_TO_DEVICE);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMemcpy failed. ERROR: %d\n", ret); return ret);

  // è®¡ç®—è¿ç»­tensorçš„strides
  std::vector<int64_t> strides(shape.size(), 1);
  for (int64_t i = shape.size() - 2; i >= 0; i--) {
    strides[i] = shape[i + 1] * strides[i + 1];
  }

  // è°ƒç”¨aclCreateTensoræ¥å£åˆ›å»ºaclTensor
  *tensor = aclCreateTensor(shape.data(), shape.size(), dataType, strides.data(), 0, aclFormat::ACL_FORMAT_ND,
                            shape.data(), shape.size(), *deviceAddr);
  return 0;
}

int main() {
  // 1. ï¼ˆå›ºå®šå†™æ³•ï¼‰device/streamåˆå§‹åŒ–ï¼Œå‚è€ƒacl APIæ‰‹å†Œ
  // æ ¹æ®è‡ªå·±çš„å®é™…deviceå¡«å†™deviceId
  int32_t deviceId = 0;
  aclrtContext context;
  aclrtStream stream;
  auto ret = Init(deviceId, &context, &stream);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("Init acl failed. ERROR: %d\n", ret); return ret);

  // 2. æ„é€ è¾“å…¥ä¸è¾“å‡ºï¼Œéœ€è¦æ ¹æ®APIçš„æ¥å£è‡ªå®šä¹‰æ„é€ 
  std::vector<int64_t> qShape = {256, 1, 128};
  std::vector<int64_t> kShape = {256, 1, 128};
  std::vector<int64_t> vShape = {256, 1, 128};
  std::vector<int64_t> dxShape = {256, 1, 128};
  std::vector<int64_t> attenmaskShape = {256, 256};
  std::vector<int64_t> softmaxMaxShape = {1, 1, 256, 8};
  std::vector<int64_t> softmaxSumShape = {1, 1, 256, 8};
  std::vector<int64_t> attentionInShape = {256, 1, 128};

  std::vector<int64_t> dqShape = {256, 1, 128};
  std::vector<int64_t> dkShape = {256, 1, 128};
  std::vector<int64_t> dvShape = {256, 1, 128};

  void* qDeviceAddr = nullptr;
  void* kDeviceAddr = nullptr;
  void* vDeviceAddr = nullptr;
  void* dxDeviceAddr = nullptr;
  void* attenmaskDeviceAddr = nullptr;
  void* softmaxMaxDeviceAddr = nullptr;
  void* softmaxSumDeviceAddr = nullptr;
  void* attentionInDeviceAddr = nullptr;
  void* dqDeviceAddr = nullptr;
  void* dkDeviceAddr = nullptr;
  void* dvDeviceAddr = nullptr;

  aclTensor* q = nullptr;
  aclTensor* k = nullptr;
  aclTensor* v = nullptr;
  aclTensor* dx = nullptr;
  aclTensor* pse = nullptr;
  aclTensor* dropMask = nullptr;
  aclTensor* padding = nullptr;
  aclTensor* attenmask = nullptr;
  aclTensor* softmaxMax = nullptr;
  aclTensor* softmaxSum = nullptr;
  aclTensor* softmaxIn = nullptr;
  aclTensor* attentionIn = nullptr;
  aclTensor* dq = nullptr;
  aclTensor* dk = nullptr;
  aclTensor* dv = nullptr;
  aclTensor* dpse = nullptr;

  std::vector<float> qHostData(32768, 1);
  std::vector<float> kHostData(32768, 1);
  std::vector<float> vHostData(32768, 1);
  std::vector<float> dxHostData(32768, 1);
  std::vector<uint8_t> attenmaskHostData(65536, 0);
  std::vector<float> softmaxMaxHostData(2048, 3.0);
  std::vector<float> softmaxSumHostData(2048, 3.0);
  std::vector<float> attentionInHostData(32768, 1);
  std::vector<float> dqHostData(32768, 0);
  std::vector<float> dkHostData(32768, 0);
  std::vector<float> dvHostData(32768, 0);

  ret = CreateAclTensor(qHostData, qShape, &qDeviceAddr, aclDataType::ACL_FLOAT16, &q);
  CHECK_RET(ret == ACL_SUCCESS, return ret);
  ret = CreateAclTensor(kHostData, kShape, &kDeviceAddr, aclDataType::ACL_FLOAT16, &k);
  CHECK_RET(ret == ACL_SUCCESS, return ret);
  ret = CreateAclTensor(vHostData, vShape, &vDeviceAddr, aclDataType::ACL_FLOAT16, &v);
  CHECK_RET(ret == ACL_SUCCESS, return ret);
  ret = CreateAclTensor(dxHostData, dxShape, &dxDeviceAddr, aclDataType::ACL_FLOAT16, &dx);
  CHECK_RET(ret == ACL_SUCCESS, return ret);
  ret = CreateAclTensor(attenmaskHostData, attenmaskShape, &attenmaskDeviceAddr, aclDataType::ACL_UINT8, &attenmask);
  CHECK_RET(ret == ACL_SUCCESS, return ret);
  ret = CreateAclTensor(softmaxMaxHostData, softmaxMaxShape, &softmaxMaxDeviceAddr, aclDataType::ACL_FLOAT, &softmaxMax);
  CHECK_RET(ret == ACL_SUCCESS, return ret);
  ret = CreateAclTensor(softmaxSumHostData, softmaxSumShape, &softmaxSumDeviceAddr, aclDataType::ACL_FLOAT, &softmaxSum);
  CHECK_RET(ret == ACL_SUCCESS, return ret);
  ret = CreateAclTensor(attentionInHostData, attentionInShape, &attentionInDeviceAddr, aclDataType::ACL_FLOAT16, &attentionIn);
  CHECK_RET(ret == ACL_SUCCESS, return ret);
  ret = CreateAclTensor(dqHostData, dqShape, &dqDeviceAddr, aclDataType::ACL_FLOAT16, &dq);
  CHECK_RET(ret == ACL_SUCCESS, return ret);
  ret = CreateAclTensor(dkHostData, dkShape, &dkDeviceAddr, aclDataType::ACL_FLOAT16, &dk);
  CHECK_RET(ret == ACL_SUCCESS, return ret);
  ret = CreateAclTensor(dvHostData, dvShape, &dvDeviceAddr, aclDataType::ACL_FLOAT16, &dv);
  CHECK_RET(ret == ACL_SUCCESS, return ret);

  std::vector<int64_t> prefixOp = {0};
  aclIntArray *prefix = aclCreateIntArray(prefixOp.data(), 1);
  double scaleValue = 0.088388;
  double keepProb = 1;
  int64_t preTokens = 65536;
  int64_t nextTokens = 65536;
  int64_t headNum = 1;
  int64_t innerPrecise = 0;
  int64_t sparseMode = 0;

  char layOut[5] = {'S', 'B', 'H', 0};

  // 3. è°ƒç”¨CANNç®—å­åº“APIï¼Œéœ€è¦ä¿®æ”¹ä¸ºå…·ä½“çš„Apiåç§°
  uint64_t workspaceSize = 0;
  aclOpExecutor* executor;

  // è°ƒç”¨aclnnFlashAttentionScoreGradç¬¬ä¸€æ®µæ¥å£
  ret = aclnnFlashAttentionScoreGradGetWorkspaceSize(q, k, v, dx, pse, dropMask, padding,
            attenmask, softmaxMax, softmaxSum, softmaxIn, attentionIn, prefix,
            scaleValue, keepProb, preTokens, nextTokens, headNum, layOut, innerPrecise, sparseMode,
            dq, dk, dv, dpse, &workspaceSize, &executor);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnFlashAttentionScoreGradGetWorkspaceSize failed. ERROR: %d\n", ret); return ret);

  // æ ¹æ®ç¬¬ä¸€æ®µæ¥å£è®¡ç®—å‡ºçš„workspaceSizeç”³è¯·deviceå†…å­˜
  void* workspaceAddr = nullptr;
  if (workspaceSize > 0) {
    ret = aclrtMalloc(&workspaceAddr, workspaceSize, ACL_MEM_MALLOC_HUGE_FIRST);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("allocate workspace failed. ERROR: %d\n", ret); return ret);
  }

  // è°ƒç”¨aclnnFlashAttentionScoreGradç¬¬äºŒæ®µæ¥å£
  ret = aclnnFlashAttentionScoreGrad(workspaceAddr, workspaceSize, executor, stream);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnFlashAttentionScoreGrad failed. ERROR: %d\n", ret); return ret);

  // 4. ï¼ˆå›ºå®šå†™æ³•ï¼‰åŒæ­¥ç­‰å¾…ä»»åŠ¡æ‰§è¡Œç»“æŸ
  ret = aclrtSynchronizeStream(stream);
  CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSynchronizeStream failed. ERROR: %d\n", ret); return ret);

  // 5. è·å–è¾“å‡ºçš„å€¼ï¼Œå°†deviceä¾§å†…å­˜ä¸Šçš„ç»“æœæ‹·è´è‡³hostä¾§ï¼Œéœ€è¦æ ¹æ®å…·ä½“APIçš„æ¥å£å®šä¹‰ä¿®æ”¹
  PrintOutResult(dqShape, &dqDeviceAddr);
  PrintOutResult(dkShape, &dkDeviceAddr);
  PrintOutResult(dvShape, &dvDeviceAddr);

  // 6. é‡Šæ”¾aclTensorå’ŒaclScalarï¼Œéœ€è¦æ ¹æ®å…·ä½“APIçš„æ¥å£å®šä¹‰ä¿®æ”¹
  aclDestroyTensor(q);
  aclDestroyTensor(k);
  aclDestroyTensor(v);
  aclDestroyTensor(dx);
  aclDestroyTensor(attenmask);
  aclDestroyTensor(softmaxMax);
  aclDestroyTensor(softmaxSum);
  aclDestroyTensor(attentionIn);
  aclDestroyTensor(dq);
  aclDestroyTensor(dk);
  aclDestroyTensor(dv);

  // 7. é‡Šæ”¾deviceèµ„æº
  aclrtFree(qDeviceAddr);
  aclrtFree(kDeviceAddr);
  aclrtFree(vDeviceAddr);
  aclrtFree(dxDeviceAddr);
  aclrtFree(attenmaskDeviceAddr);
  aclrtFree(softmaxMaxDeviceAddr);
  aclrtFree(softmaxSumDeviceAddr);
  aclrtFree(attentionInDeviceAddr);
  aclrtFree(dqDeviceAddr);
  aclrtFree(dkDeviceAddr);
  aclrtFree(dvDeviceAddr);
  if (workspaceSize > 0) {
    aclrtFree(workspaceAddr);
  }
  aclrtDestroyStream(stream);
  aclrtDestroyContext(context);
  aclrtResetDevice(deviceId);
  aclFinalize();

  return 0;
}
```

