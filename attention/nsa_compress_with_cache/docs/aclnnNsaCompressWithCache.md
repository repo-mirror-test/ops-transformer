## aclnnNsaCompressWithCache

[ğŸ“„ æŸ¥çœ‹æºç ](https://gitcode.com/cann/ops-transformer/tree/master/attention/nsa_compress_with_cache)

## äº§å“æ”¯æŒæƒ…å†µ

|äº§å“      | æ˜¯å¦æ”¯æŒ |
|:----------------------------|:-----------:|
|<term>æ˜‡è…¾910_95 AIå¤„ç†å™¨</term>|      Ã—     |
|<term>Atlas A3 è®­ç»ƒç³»åˆ—äº§å“/Atlas A3 æ¨ç†ç³»åˆ—äº§å“</term>|      âˆš     |
|<term>Atlas A2 è®­ç»ƒç³»åˆ—äº§å“/Atlas 800I A2 æ¨ç†äº§å“/A200I A2 Box å¼‚æ„ç»„ä»¶</term>|      âˆš     |
|<term>Atlas 200I/500 A2 æ¨ç†äº§å“</term>|      Ã—     |
|<term>Atlas æ¨ç†ç³»åˆ—äº§å“</term>|      Ã—     |
|<term>Atlas è®­ç»ƒç³»åˆ—äº§å“</term>|      Ã—     |
|<term>Atlas 200I/300/500 æ¨ç†äº§å“</term>|      Ã—     |

## åŠŸèƒ½è¯´æ˜

- æ¥å£åŠŸèƒ½ï¼šç”¨äºNative-Sparse-Attentionæ¨ç†é˜¶æ®µçš„KVå‹ç¼©ï¼Œæ¯æ¬¡æ¨ç†æ¯ä¸ªbatchä¼šäº§ç”Ÿä¸€ä¸ªæ–°çš„tokenï¼Œæ¯å½“æŸä¸ªbatchçš„tokenæ•°é‡å‡‘æ»¡ä¸€ä¸ªcompress_blockæ—¶ï¼Œè¯¥ç®—å­ä¼šå°†è¯¥batchçš„åcompress_blockä¸ªtokenå‹ç¼©æˆä¸€ä¸ªcompress_tokenã€‚
- è®¡ç®—å…¬å¼ï¼š

$$
compressIdx=(s-compressBlockSize)/stride\\ 
outputCacheRef[slotMapping[i]] = input[compressIdx*stride : compressIdx*stride+compressBlockSize]*weight[:]
$$

## å‡½æ•°åŸå‹

æ¯ä¸ªç®—å­åˆ†ä¸º[ä¸¤æ®µå¼æ¥å£](../../../docs/zh/context/ä¸¤æ®µå¼æ¥å£.md)ï¼Œå¿…é¡»å…ˆè°ƒç”¨â€œaclnnNsaCompressWithCacheGetWorkspaceSizeâ€æ¥å£è·å–è®¡ç®—æ‰€éœ€workspaceå¤§å°ä»¥åŠåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹çš„æ‰§è¡Œå™¨ï¼Œå†è°ƒç”¨â€œaclnnNsaCompressWithCacheâ€æ¥å£æ‰§è¡Œè®¡ç®—ã€‚

```c++
aclnnStatus aclnnNsaCompressWithCacheGetWorkspaceSize(
   const aclTensor   *input,
   const aclTensor   *weight,
   const aclTensor   *slotMapping,
   const aclIntArray *actSeqLenOptional,
   const aclTensor   *blockTableOptional,
   char              *layoutOptional,
   int64_t            compressBlockSize,
   int64_t            compressStride,
   int64_t            actSeqLenType,
   int64_t            pageBlockSize,
   aclTensor         *outputCache,
   uint64_t          *workspaceSize,
   aclOpExecutor    **executor)
```

```c++
aclnnStatus aclnnNsaCompressWithCache(
   void          *workspace,
   uint64_t       workspaceSize,
   aclOpExecutor *executor,
   aclrtStream    stream)
```

## aclnnNsaCompressWithCacheGetWorkspaceSize

- **å‚æ•°è¯´æ˜**
  
  <table style="undefined; table-layout: fixed; width: 1567px">
    <colgroup>
      <col style="width: 170px"> <!-- å‚æ•°å -->
      <col style="width: 120px"> <!-- è¾“å…¥/è¾“å‡º -->
      <col style="width: 300px"> <!-- æè¿° -->
      <col style="width: 330px"> <!-- ä½¿ç”¨è¯´æ˜ -->
      <col style="width: 212px"> <!-- æ•°æ®ç±»å‹ -->
      <col style="width: 100px"> <!-- æ•°æ®æ ¼å¼ -->
      <col style="width: 190px"> <!-- ç»´åº¦(shape) -->
      <col style="width: 145px"> <!-- éè¿ç»­Tensor -->
    </colgroup>
    <thead>
      <tr>
        <th>å‚æ•°å</th>
        <th>è¾“å…¥/è¾“å‡º</th>
        <th>æè¿°</th>
        <th>ä½¿ç”¨è¯´æ˜</th>
        <th>æ•°æ®ç±»å‹</th>
        <th>æ•°æ®æ ¼å¼</th>
        <th>ç»´åº¦(shape)</th>
        <th>éè¿ç»­Tensor</th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>input</td>
        <td>è¾“å…¥</td>
        <td>å¾…å‹ç¼©å¼ é‡ã€‚</td>
        <td>
          <ul style="list-style-type: circle;">
            <li>ä¸æ”¯æŒç©ºTensorã€‚</li>
            <li>inputå’Œweightæ»¡è¶³broadcastå…³ç³»ï¼Œinputçš„ç¬¬ä¸‰ç»´å¤§å°ä¸weightçš„ç¬¬äºŒç»´å¤§å°ç›¸ç­‰ã€‚</li>
            <li>headDimæ˜¯16çš„æ•´æ•°å€ï¼Œä¸”headDim<=256ã€‚</li>
            <li>headNum<=64ï¼Œä¸”headNum>50æ—¶headNum%2=0ã€‚</li>
            <li>Nï¼ˆHead-Numï¼‰è¡¨ç¤ºå¤šå¤´æ•°ã€Dï¼ˆHead-Dimï¼‰è¡¨ç¤ºéšè—å±‚æœ€å°çš„å•å…ƒå°ºå¯¸ã€‚</li>
          </ul>
        </td>
        <td>FLOAT16ã€BFLOAT16</td>
        <td>ND</td>
        <td>[blockNum, pageBlockSize, N, D]ã€[TND]</td>
        <td>âˆš</td>
      </tr>
      <tr>
        <td>weight</td>
        <td>è¾“å…¥</td>
        <td>å‹ç¼©çš„æƒé‡ã€‚</td>
        <td>
          <ul style="list-style-type: circle;">
            <li>ä¸æ”¯æŒç©ºTensorã€‚</li>
            <li>æ•°æ®ç±»å‹ä¸inputä¿æŒä¸€è‡´ã€‚</li>
            <li>Nï¼ˆHead-Numï¼‰è¡¨ç¤ºå¤šå¤´æ•°ã€‚</li>
          </ul>
        </td>
        <td>FLOAT16ã€BFLOAT16</td>
        <td>ND</td>
        <td>[compressBlockSize, N]</td>
        <td>âˆš</td>
      </tr>
      <tr>
        <td>slotMapping</td>
        <td>è¾“å…¥</td>
        <td>æ¯ä¸ªbatchå°¾éƒ¨å‹ç¼©æ•°æ®å­˜å‚¨çš„ä½ç½®çš„ç´¢å¼•ã€‚</td>
        <td>
          <ul style="list-style-type: circle;">
            <li>ä¸æ”¯æŒç©ºTensorã€‚</li>
            <li>slotMappingçš„å€¼æ— é‡å¤ï¼Œå¦åˆ™ä¼šå¯¼è‡´è®¡ç®—ç»“æœä¸ç¨³å®šã€‚</li>
          </ul>
        </td>
        <td>INT32</td>
        <td>ND</td>
        <td>[B]</td>
        <td>x</td>
      </tr>
      <tr>
        <td>actSeqLenOptional</td>
        <td>å¯é€‰è¾“å…¥</td>
        <td>æ¯ä¸ªBatchå¯¹åº”çš„Så¤§å°ã€‚</td>
        <td>
          <ul style="list-style-type: circle;">
            <li>åœ¨TNDæ’å¸ƒåœºæ™¯ä¸‹éœ€è¦è¯¥è¾“å…¥ï¼Œå…¶ä½™åœºæ™¯è¾“å…¥nullptrã€‚</li>
            <li>Sï¼ˆSeq-Lengthï¼‰è¡¨ç¤ºè¾“å…¥æ ·æœ¬åºåˆ—é•¿åº¦ã€‚</li>
            <li>actSeqLenOptionalçš„å€¼ä¸åº”è¯¥è¶…è¿‡åºåˆ—æœ€å¤§é•¿åº¦ã€‚</li>
          </ul>
        </td>
        <td>INT64</td>
        <td>ND</td>
        <td>[B]</td>
        <td>-</td>
      </tr>
      <tr>
        <td>blockTableOptional</td>
        <td>å¯é€‰è¾“å…¥</td>
        <td>PageAttentionä¸­KVå­˜å‚¨ä½¿ç”¨çš„blockæ˜ å°„è¡¨ã€‚</td>
        <td>
          <ul style="list-style-type: circle;">
            <li>ä½¿ç”¨è¯¥åŠŸèƒ½å¯ä¼ å…¥nullptrã€‚</li>
            <li>blockTableOptionalçš„å€¼ä¸è¶…è¿‡blockNumï¼Œå¦åˆ™ä¼šå‘ç”Ÿè¶Šç•Œã€‚</li>
          </ul>
        </td>
        <td>INT32</td>
        <td>ND</td>
        <td>[batch, blockNumPerBatch]</td>
        <td>-</td>
      </tr>
      <tr>
        <td>layoutOptional</td>
        <td>å¯é€‰è¾“å…¥</td>
        <td>è¾“å…¥inputçš„æ•°æ®æ’å¸ƒæ ¼å¼ã€‚</td>
        <td>
          <ul style="list-style-type: circle;">
            <li>å½“å‰ä»…æ”¯æŒ"TND"ï¼Œå½“ä¼ å…¥blockTableOptionalæ—¶æ­¤å‚æ•°æ— æ•ˆï¼Œå¦åˆ™ä¸ºå¿…é€‰å‚æ•°ã€‚</li>
            <li>å…¶ä¸­Tæ˜¯Bå’ŒSåˆè½´ç´§å¯†æ’åˆ—çš„æ•°æ®ï¼ˆæ¯ä¸ªbatchçš„actSeqLenï¼‰ã€Bï¼ˆBatchï¼‰è¡¨ç¤ºè¾“å…¥æ ·æœ¬æ‰¹é‡å¤§å°ã€Sï¼ˆSeq-Lengthï¼‰è¡¨ç¤ºè¾“å…¥æ ·æœ¬åºåˆ—é•¿åº¦ã€Nï¼ˆHead-Numï¼‰è¡¨ç¤ºå¤šå¤´æ•°ã€Dï¼ˆHead-Dimï¼‰è¡¨ç¤ºéšè—å±‚æœ€å°çš„å•å…ƒå°ºå¯¸ã€‚</li>
          </ul>
        </td>
        <td>CHAR</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td>compressBlockSize</td>
        <td>è¾“å…¥</td>
        <td>å‹ç¼©æ»‘çª—å¤§å°ã€‚</td>
        <td>å¿…é¡»æ˜¯16çš„æ•´æ•°å€ï¼Œä¸”compressBlockSize>=compressStrideï¼ŒcompressBlockSize<=64ã€‚</td>
        <td>INT64</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td>compressStride</td>
        <td>è¾“å…¥</td>
        <td>ä¸¤æ¬¡å‹ç¼©é—´çš„æ»‘çª—é—´éš”å¤§å°ã€‚</td>
        <td>ä»…æ”¯æŒcompressBlockStrideå–å€¼16ã€32ã€48ã€64ã€‚</td>
        <td>INT64</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td>actSeqLenType</td>
        <td>è¾“å…¥</td>
        <td>actSeqLenOptionalçš„ä¸åŒè¡¨è¾¾å½¢å¼</td>
        <td>actSeqLenOptionalæœ‰è¾“å…¥æ—¶ç”Ÿæ•ˆï¼Œå¯å–å€¼0æˆ–1ï¼Œ0ä»£è¡¨actSeqLenOptionalä¸­æ•°å€¼ä¸ºå‰ç»§batchçš„åºåˆ—å¤§å°çš„cumsumç»“æœï¼ˆç´¯ç§¯å’Œï¼‰ï¼Œ1ä»£è¡¨actSeqLenOptionalä¸­æ•°å€¼ä¸ºæ¯ä¸ªbatchä¸­åºåˆ—å¤§å°ï¼Œå½“å‰ä»…æ”¯æŒ1ã€‚</td>
        <td>INT64</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td>pageBlockSize</td>
        <td>è¾“å…¥</td>
        <td>page attentionåœºæ™¯ä¸‹pageçš„blocksizeå¤§å°ã€‚</td>
        <td>åªèƒ½æ˜¯64æˆ–è€…128ã€‚</td>
        <td>INT64</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td>outputCache</td>
        <td>è¾“å‡º</td>
        <td>å‹ç¼©ä¹‹åçš„cache</td>
        <td>æ•°æ®ç±»å‹ä¸inputä¿æŒä¸€è‡´ã€‚</td>
        <td>INT64</td>
        <td>-</td>
        <td>[result_len, N, D]</td>
        <td>x</td>
      </tr>
      <tr>
        <td>workspaceSize</td>
        <td>è¾“å‡º</td>
        <td>è¿”å›éœ€è¦åœ¨Deviceä¾§ç”³è¯·çš„workspaceå¤§å°ã€‚</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td>executor</td>
        <td>è¾“å‡º</td>
        <td>è¿”å›opæ‰§è¡Œå™¨ï¼ŒåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹ã€‚</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
    </tbody>
  </table>
- **è¿”å›å€¼**

  aclnnStatusï¼šè¿”å›çŠ¶æ€ç ï¼Œå…·ä½“å‚è§[aclnnè¿”å›ç ](../../../docs/zh/context/aclnnè¿”å›ç .md)ã€‚
  
  ç¬¬ä¸€æ®µæ¥å£å®Œæˆå…¥å‚æ ¡éªŒï¼Œå‡ºç°ä»¥ä¸‹åœºæ™¯æ—¶æŠ¥é”™ï¼š
  
  <table style="undefined;table-layout: fixed; width: 1030px">
  <colgroup>
  <col style="width: 250px">
  <col style="width: 130px">
  <col style="width: 650px">
  </colgroup>
    <table><thead>
    <tr>
      <th>è¿”å›å€¼</th>
      <th>é”™è¯¯ç </th>
      <th>æè¿°</th>
    </tr></thead>
  <tbody>
    <tr>
      <td>ACLNN_ERR_PARAM_NULLPTR</td>
      <td>161001</td>
      <td>è®¡ç®—è¾“å…¥å’Œå¿…é€‰è®¡ç®—è¾“å‡ºæ˜¯ç©ºæŒ‡é’ˆã€‚</td>
    </tr>
    <tr>
      <td>ACLNN_ERR_PARAM_INVALID</td>
      <td>161002</td>
      <td>è®¡ç®—è¾“å…¥å’Œè¾“å‡ºçš„æ•°æ®ç±»å‹å’Œæ ¼å¼ä¸åœ¨æ”¯æŒçš„èŒƒå›´å†…ã€‚</td>
    </tr>
    <tr>
      <td rowspan="6">ACLNN_ERR_RUNTIME_ERROR</td>
      <td rowspan="6">561002</td>
      <td>inputå’Œweightä¸æ»¡è¶³broadcastå…³ç³»ï¼Œå³inputçš„ç¬¬ä¸‰ç»´å¤§å°ä¸weightçš„ç¬¬äºŒç»´å¤§å°ä¸ç›¸ç­‰ã€‚</td>
    </tr>
    <tr>
      <td>activeNumã€expertNumã€expertCapacityçš„å€¼å°äº0ã€‚</td>
    </tr>
    <tr>
      <td>compress_block_sizeã€compress_stride ã€ä¸æ˜¯16çš„æ•´æ•°å€ï¼Œæˆ–è€…compress_block_size<compress_strideã€‚</td>
    </tr>
    <tr>
      <td>seq_lens_type!=1æˆ–è€…layoutå–å€¼ä¸æ˜¯BSHã€SBHã€BSNDã€BNSDã€TNDä¸­çš„ä¸€ä¸ªã€‚</td>
    </tr>
    <tr>
      <td>page_block_sizeå–å€¼ä¸æ˜¯64æˆ–è€…128ã€‚</td>
    </tr>
    <tr>
      <td>headDimæœªå¯¹é½16ã€‚</td>
    </tr>
  </tbody>
  </table>

## aclnnNsaCompressAttentionInfer

- **å‚æ•°è¯´æ˜**
  
  <table><thead>
    <tr>
      <th>å‚æ•°å</th>
      <th>è¾“å…¥/è¾“å‡º</th>
      <th>æè¿°</th>
    </tr></thead>
  <tbody>
    <tr>
      <td>workspace</td>
      <td>è¾“å…¥</td>
      <td>åœ¨Deviceä¾§ç”³è¯·çš„workspaceå†…å­˜åœ°å€ã€‚</td>
    </tr>
    <tr>
      <td>workspaceSize</td>
      <td>è¾“å…¥</td>
      <td>åœ¨Deviceä¾§ç”³è¯·çš„workspaceå¤§å°ï¼Œç”±ç¬¬ä¸€æ®µæ¥å£aclnnNsaCompressWithCacheè·å–ã€‚</td>
    </tr>
    <tr>
      <td>executor</td>
      <td>è¾“å…¥</td>
      <td>opæ‰§è¡Œå™¨ï¼ŒåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹ã€‚</td>
    </tr>
    <tr>
      <td>stream</td>
      <td>è¾“å…¥</td>
      <td>æŒ‡å®šæ‰§è¡Œä»»åŠ¡çš„Streamã€‚</td>
    </tr>
  </tbody>
  </table>
- **è¿”å›å€¼**
  
  aclnnStatusï¼šè¿”å›çŠ¶æ€ç ï¼Œå…·ä½“å‚è§[aclnnè¿”å›ç ](../../../docs/zh/context/aclnnè¿”å›ç .md)ã€‚

## çº¦æŸè¯´æ˜

- ç¡®å®šæ€§è®¡ç®—ï¼š
  - aclnnNsaCompressWithCacheé»˜è®¤ç¡®å®šæ€§å®ç°ã€‚
- outputCacheçš„Nå’ŒDå’Œinputä¸€è‡´ï¼Œè€Œä¸”è¦æ»¡è¶³result_len>(blockNum*pageBlockSize-compressBlockSize)/compressStrideã€‚
- page attentionåœºæ™¯ä¸‹inputçš„shapeæ”¯æŒ[blockNum,pageBlockSize,N,D]ï¼Œå…¶ä½™åœºæ™¯ä¸‹inputçš„shapeæ”¯æŒ[T,N,D]ã€‚

## è°ƒç”¨ç¤ºä¾‹

ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼Œä»…ä¾›å‚è€ƒï¼Œå…·ä½“ç¼–è¯‘å’Œæ‰§è¡Œè¿‡ç¨‹è¯·å‚è€ƒ[ç¼–è¯‘ä¸è¿è¡Œæ ·ä¾‹](../../../docs/zh/context/ç¼–è¯‘ä¸è¿è¡Œæ ·ä¾‹.md)ã€‚

```c++
#include "acl/acl.h"
#include "aclnnop/aclnn_nsa_compress_with_cache.h"
#include <iostream>
#include <vector>
#define CHECK_RET(cond, return_expr) \
  do {                               \
    if (!(cond)) {                   \
      return_expr;                   \
    }                                \
  } while (0)
#define LOG_PRINT(message, ...)     \
  do {                              \
    printf(message, ##__VA_ARGS__); \
  } while (0)
int64_t GetShapeSize(const std::vector<int64_t>& shape) {
    int64_t shape_size = 1;
    for (auto i : shape) {
        shape_size *= i;
    }
    return shape_size;
}
int Init(int32_t deviceId, aclrtStream* stream) {
    // å›ºå®šå†™æ³•ï¼Œèµ„æºåˆå§‹åŒ–
    auto ret = aclInit(nullptr);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclInit failed. ERROR: %d\n", ret); return ret);
    ret = aclrtSetDevice(deviceId);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSetDevice failed. ERROR: %d\n", ret); return ret);
    ret = aclrtCreateStream(stream);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtCreateStream failed. ERROR: %d\n", ret); return ret);
    return 0;
}
template <typename T>
int CreateAclTensor(const std::vector<T>& hostData, const std::vector<int64_t>& shape, void** deviceAddr,
                    aclDataType dataType, aclTensor** tensor) {
    auto size = GetShapeSize(shape) * sizeof(T);
    // è°ƒç”¨aclrtMallocç”³è¯·deviceä¾§å†…å­˜
    auto ret = aclrtMalloc(deviceAddr, size, ACL_MEM_MALLOC_HUGE_FIRST);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMalloc failed. ERROR: %d\n", ret); return ret);
    // è°ƒç”¨aclrtMemcpyå°†hostä¾§æ•°æ®æ‹·è´åˆ°deviceä¾§å†…å­˜ä¸Š
    ret = aclrtMemcpy(*deviceAddr, size, hostData.data(), size, ACL_MEMCPY_HOST_TO_DEVICE);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMemcpy failed. ERROR: %d\n", ret); return ret);
    // è®¡ç®—è¿ç»­tensorçš„strides
    std::vector<int64_t> strides(shape.size(), 1);
    for (int64_t i = shape.size() - 2; i >= 0; i--) {
        strides[i] = shape[i + 1] * strides[i + 1];
    }
    // è°ƒç”¨aclCreateTensoræ¥å£åˆ›å»ºaclTensor
    *tensor = aclCreateTensor(shape.data(), shape.size(), dataType, strides.data(), 0, aclFormat::ACL_FORMAT_ND,
                              shape.data(), shape.size(), *deviceAddr);
    return 0;
}
int main() {
    // è¾“å…¥shapeç›¸å…³å‚æ•°è®¾ç½®
    constexpr int64_t compress_block_size = 32;
    constexpr int64_t compress_stride = 16;
    constexpr int64_t heads_num = 24;
    constexpr int64_t heads_dim = 192;
    constexpr int64_t batch_size = 4;
    constexpr int64_t page_block_size = 128;
    constexpr int64_t max_seq_len = 512;
    constexpr int64_t result_len = 512;
    constexpr int64_t block_num_per_batch = max_seq_len / page_block_size;
    constexpr int64_t blocks_num = block_num_per_batch * batch_size;
    // 1. å›ºå®šå†™æ³•ï¼Œdevice/streamåˆå§‹åŒ–, å‚è€ƒaclå¯¹å¤–æ¥å£åˆ—è¡¨
    // æ ¹æ®è‡ªå·±çš„å®é™…deviceå¡«å†™deviceId
    int32_t deviceId = 0;
    aclrtStream stream;
    auto ret = Init(deviceId, &stream);
    // checkæ ¹æ®è‡ªå·±çš„éœ€è¦å¤„ç†
    CHECK_RET(ret == 0, LOG_PRINT("Init acl failed. ERROR: %d\n", ret); return ret);
    // 2. æ„é€ è¾“å…¥ä¸è¾“å‡ºï¼Œéœ€è¦æ ¹æ®APIçš„æ¥å£å®šä¹‰æ„é€ 
    std::vector<int64_t> inputShape = {blocks_num, page_block_size, heads_num, heads_dim};
    std::vector<int64_t> weightShape = {compress_block_size, heads_num};
    std::vector<int64_t> slotMappingShape = {batch_size};
    std::vector<int64_t> outputCacheRefShape = {result_len, heads_num, heads_dim};
    std::vector<int64_t> actSeqLenShape = {batch_size};
    std::vector<int64_t> blockTableShape = {batch_size, block_num_per_batch};

    void *inputDeviceAddr = nullptr;
    void *weightDeviceAddr = nullptr;
    void *slotMappingDeviceAddr = nullptr;
    void *outputCacheRefDeviceAddr = nullptr;
    void *actSeqLenDeviceAddr = nullptr;
    void *blockTableDeviceAddr = nullptr;

    aclTensor *input = nullptr;
    aclTensor *weight = nullptr;
    aclTensor *slotMapping = nullptr;
    aclTensor *outputCacheRef = nullptr;
    aclIntArray *actSeqLen = nullptr;
    aclTensor *blockTable = nullptr;

    std::vector<aclFloat16> inputHostData(inputShape[0] * inputShape[1] * inputShape[2] * inputShape[3],
                                          aclFloatToFloat16(1.0));
    std::vector<aclFloat16> weightHostData(weightShape[0] * weightShape[1], aclFloatToFloat16(1.0));
    std::vector<int32_t> slotMappingHostData(slotMappingShape[0], 0);
    std::vector<aclFloat16> outputCacheRefHostData(outputCacheRefShape[0] * outputCacheRefShape[1] *
                                                   outputCacheRefShape[2], aclFloatToFloat16(1.0));
    std::vector<int64_t> actSeqLenHostData(actSeqLenShape[0], 0);
    std::vector<int32_t> blockTableHostData(blockTableShape[0] * blockTableShape[1]);
    actSeqLenHostData[0]=32;
    // åˆ›å»ºself aclTensor
    ret = CreateAclTensor(inputHostData, inputShape, &inputDeviceAddr, aclDataType::ACL_FLOAT16, &input);
    CHECK_RET(ret == ACL_SUCCESS, return ret);
    ret = CreateAclTensor(weightHostData, weightShape, &weightDeviceAddr, aclDataType::ACL_FLOAT16, &weight);
    CHECK_RET(ret == ACL_SUCCESS, return ret);
    ret = CreateAclTensor(slotMappingHostData, slotMappingShape, &slotMappingDeviceAddr, aclDataType::ACL_INT32,
                          &slotMapping);
    CHECK_RET(ret == ACL_SUCCESS, return ret);
    ret = CreateAclTensor(outputCacheRefHostData, outputCacheRefShape, &outputCacheRefDeviceAddr,
                          aclDataType::ACL_FLOAT16, &outputCacheRef);
    CHECK_RET(ret == ACL_SUCCESS, return ret);
    actSeqLen = aclCreateIntArray(actSeqLenHostData.data(), actSeqLenHostData.size());
    ret = CreateAclTensor(blockTableHostData, blockTableShape, &blockTableDeviceAddr, aclDataType::ACL_INT32,
                          &blockTable);
    CHECK_RET(ret == ACL_SUCCESS, return ret);
    char layout[4] = "TND";
    int64_t actSeqLenType = 1;
    // 3. è°ƒç”¨CANNç®—å­åº“APIï¼Œéœ€è¦ä¿®æ”¹ä¸ºå…·ä½“çš„API
    uint64_t workspaceSize = 0;
    aclOpExecutor* executor;
    // è°ƒç”¨aclnnNsaCompressWithCacheç¬¬ä¸€æ®µæ¥å£
    ret = aclnnNsaCompressWithCacheGetWorkspaceSize(input, weight, slotMapping, actSeqLen, blockTable, layout,
                                                    compress_block_size, compress_stride, actSeqLenType,
                                                    page_block_size, outputCacheRef, &workspaceSize, &executor);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnNsaCompressWithCacheGetWorkspaceSize failed. ERROR: %d\n", ret);
              return ret);
    // æ ¹æ®ç¬¬ä¸€æ®µæ¥å£è®¡ç®—å‡ºçš„workspaceSizeç”³è¯·deviceå†…å­˜
    void* workspaceAddr = nullptr;
    if (workspaceSize > 0) {
        ret = aclrtMalloc(&workspaceAddr, workspaceSize, ACL_MEM_MALLOC_HUGE_FIRST);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("allocate workspace failed. ERROR: %d\n", ret); return ret;);
    }
    // è°ƒç”¨aclnnNsaCompressWithCacheç¬¬äºŒæ®µæ¥å£
    ret = aclnnNsaCompressWithCache(workspaceAddr, workspaceSize, executor, stream);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnNsaCompressWithCache failed. ERROR: %d\n", ret); return ret);
    // 4. å›ºå®šå†™æ³•ï¼ŒåŒæ­¥ç­‰å¾…ä»»åŠ¡æ‰§è¡Œç»“æŸ
    ret = aclrtSynchronizeStream(stream);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSynchronizeStream failed. ERROR: %d\n", ret); return ret);
    // 5. è·å–è¾“å‡ºçš„å€¼ï¼Œå°†deviceä¾§å†…å­˜ä¸Šçš„ç»“æœæ‹·è´è‡³hostä¾§ï¼Œéœ€è¦æ ¹æ®å…·ä½“APIçš„æ¥å£å®šä¹‰ä¿®æ”¹
    auto size = GetShapeSize(outputCacheRefShape);
    std::vector<aclFloat16> resultData(size, 0);
    ret = aclrtMemcpy(resultData.data(), resultData.size() * sizeof(aclFloat16), outputCacheRefDeviceAddr,
                      size * sizeof(aclFloat16), ACL_MEMCPY_DEVICE_TO_HOST);
    CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("copy result from device to host failed. ERROR: %d\n", ret); return ret);
    for (int64_t i = heads_dim * heads_num - 16; i < heads_dim * heads_num + 16; i++) {
        printf("outputCache[%ld]:%f\n", i, aclFloat16ToFloat(resultData[i]));
    }
    // 6. é‡Šæ”¾aclTensorï¼Œéœ€è¦æ ¹æ®å…·ä½“APIçš„æ¥å£å®šä¹‰ä¿®æ”¹
    aclDestroyTensor(input);
    aclDestroyTensor(weight);
    aclDestroyTensor(slotMapping);
    aclDestroyTensor(outputCacheRef);
    aclDestroyIntArray(actSeqLen);
    aclDestroyTensor(blockTable);

    // 7. é‡Šæ”¾deviceèµ„æºï¼Œéœ€è¦æ ¹æ®å…·ä½“APIçš„æ¥å£å®šä¹‰ä¿®æ”¹
    aclrtFree(inputDeviceAddr);
    aclrtFree(weightDeviceAddr);
    aclrtFree(slotMappingDeviceAddr);
    aclrtFree(outputCacheRefDeviceAddr);
    aclrtFree(blockTableDeviceAddr);
    if (workspaceSize > 0) {
        aclrtFree(workspaceAddr);
    }
    aclrtDestroyStream(stream);
    aclrtResetDevice(deviceId);
    aclFinalize();
    return 0;
}
```
