# aclnnGroupedMatmulSwigluQuantV2

[ğŸ“„ æŸ¥çœ‹æºç ](https://gitcode.com/cann/ops-transformer/tree/master/gmm/grouped_matmul_swiglu_quant_v2)

## äº§å“æ”¯æŒæƒ…å†µ

| äº§å“                                                         | æ˜¯å¦æ”¯æŒ |
| :----------------------------------------------------------- | :------: |
| <term>æ˜‡è…¾910_95 AIå¤„ç†å™¨</term>                             |    âˆš     |
| <term>Atlas A3 è®­ç»ƒç³»åˆ—äº§å“/Atlas A3 æ¨ç†ç³»åˆ—äº§å“</term>     |    âˆš     |
| <term>Atlas A2 è®­ç»ƒç³»åˆ—äº§å“/Atlas 800I A2 æ¨ç†äº§å“/A200I A2 Box å¼‚æ„ç»„ä»¶</term> |    âˆš     |

## åŠŸèƒ½è¯´æ˜

- æ¥å£åŠŸèƒ½ï¼šèåˆGroupedMatmul ã€dequantã€swigluå’Œquantï¼Œè¯¦ç»†è§£é‡Šè§è®¡ç®—å…¬å¼ã€‚æœ¬æ¥å£ç›¸è¾ƒäº[aclnnGroupedMatmulSwigluQuant](../../grouped_matmul_swiglu_quant/docs/aclnnGroupedMatmulSwigluQuant.md)ï¼Œæ–°å¢äº†MXFP8ã€MXFP4é‡åŒ–åœºæ™¯ï¼ˆä»…æ˜‡è…¾910_95 AIå¤„ç†å™¨æ”¯æŒï¼‰ï¼Œå‚æ•°weight, weightScale, weightAssistMatrixçš„å­—æ®µç±»å‹å˜ä¸ºtensorlistï¼Œè¯·æ ¹æ®å®é™…æƒ…å†µé€‰æ‹©åˆé€‚çš„æ¥å£ã€‚
- è®¡ç®—å…¬å¼ï¼š
  - <term>Atlas A3 è®­ç»ƒç³»åˆ—äº§å“/Atlas A3 æ¨ç†ç³»åˆ—äº§å“</term>ã€<term>Atlas A2 è®­ç»ƒç³»åˆ—äº§å“/Atlas 800I A2 æ¨ç†äº§å“/A200I A2 Box å¼‚æ„ç»„ä»¶</term>ï¼š
    <details>
    <summary>é‡åŒ–åœºæ™¯A8W8ï¼ˆAæŒ‡æ¿€æ´»çŸ©é˜µï¼ŒWæŒ‡æƒé‡çŸ©é˜µï¼Œ8æŒ‡INT8æ•°æ®ç±»å‹ï¼‰ï¼š</summary>
    <a id="é‡åŒ–åœºæ™¯A8W8"></a>

      - **å®šä¹‰**ï¼š

        * **â‹…** è¡¨ç¤ºçŸ©é˜µä¹˜æ³•ã€‚
        * **âŠ™** è¡¨ç¤ºé€å…ƒç´ ä¹˜æ³•ã€‚
        * $\left \lfloor x\right \rceil$ è¡¨ç¤ºå°†xå››èˆäº”å…¥åˆ°æœ€è¿‘çš„æ•´æ•°ã€‚
        * $\mathbb{Z_8} = \{ x \in \mathbb{Z} | âˆ’128â‰¤xâ‰¤127 \}$
        * $\mathbb{Z_{32}} = \{ x \in \mathbb{Z} | -2147483648â‰¤xâ‰¤2147483647 \}$
      - **è¾“å…¥**ï¼š

        * $Xâˆˆ\mathbb{Z_8}^{M \times K}$ï¼šæ¿€æ´»çŸ©é˜µï¼ˆå·¦çŸ©é˜µï¼‰ï¼ŒMæ˜¯æ€»tokenæ•°ï¼ŒKæ˜¯ç‰¹å¾ç»´åº¦ã€‚
        * $Wâˆˆ\mathbb{Z_8}^{E \times K \times N}$ï¼šåˆ†ç»„æƒé‡çŸ©é˜µï¼ˆå³çŸ©é˜µï¼‰ï¼ŒEæ˜¯ä¸“å®¶ä¸ªæ•°ï¼ŒKæ˜¯ç‰¹å¾ç»´åº¦ï¼ŒNæ˜¯è¾“å‡ºç»´åº¦ã€‚
        * $w\_scaleâˆˆ\mathbb{R}^{E \times N}$ï¼šåˆ†ç»„æƒé‡çŸ©é˜µï¼ˆå³çŸ©é˜µï¼‰çš„é€é€šé“ç¼©æ”¾å› å­ï¼ŒEæ˜¯ä¸“å®¶ä¸ªæ•°ï¼ŒNæ˜¯è¾“å‡ºç»´åº¦ã€‚
        * $x\_scaleâˆˆ\mathbb{R}^{M}$ï¼šæ¿€æ´»çŸ©é˜µï¼ˆå·¦çŸ©é˜µï¼‰çš„é€ tokenç¼©æ”¾å› å­ï¼ŒMæ˜¯æ€»tokenæ•°ã€‚
        * $grouplistâˆˆ\mathbb{N}^{E}$ï¼šcumsumæˆ–countçš„åˆ†ç»„ç´¢å¼•åˆ—è¡¨ã€‚
      - **è¾“å‡º**ï¼š

        * $Qâˆˆ\mathbb{Z_8}^{M \times N / 2}$ï¼šé‡åŒ–åçš„è¾“å‡ºçŸ©é˜µã€‚
        * $Q\_scaleâˆˆ\mathbb{R}^{M}$ï¼šé‡åŒ–ç¼©æ”¾å› å­ã€‚

      - **è®¡ç®—è¿‡ç¨‹**

        - 1.æ ¹æ®groupList[i]ç¡®å®šå½“å‰åˆ†ç»„çš„ token ï¼Œ$i \in [0,Len(groupList)]$ã€‚

          >ä¾‹å­ï¼šå‡è®¾groupList=[3,4,4,6]ã€groupListType=cumsumæˆ–groupList=[3,1,0,2]ã€groupListType=countã€‚
          >
          >æ³¨ï¼šä»¥ä¸Šä¸¤ç§ä¸åŒçš„åˆ†ç»„æ–¹å¼ï¼Œå®é™…ä¸ºç›¸åŒçš„åˆ†ç»„ç»“æœã€‚
          >
          >ç¬¬0ä¸ªå³çŸ©é˜µ`W[0,:,:]`ï¼Œå¯¹åº”ç´¢å¼•ä½ç½®[0,3)çš„token`x[0:3]`ï¼ˆå…±3-0=3ä¸ªtokenï¼‰ï¼Œå¯¹åº”`x_scale[0:3]`ã€`w_scale[0]`ã€`bias[0]`ã€`offset[0] `ã€`Q[0:3]`ã€`Q_scale[0:3]`ã€`Q_offset[0:3]`ï¼›
          >
          >ç¬¬1ä¸ªå³çŸ©é˜µ`W[1,:,:]`ï¼Œå¯¹åº”ç´¢å¼•ä½ç½®[3,4)çš„token`x[3:4]`ï¼ˆå…±4-3=1ä¸ªtokenï¼‰ï¼Œå¯¹åº”`x_scale[3:4]`ã€`w_scale[1]`ã€`bias[1]`ã€`offset[1] `ã€`Q[3:4]`ã€`Q_scale[3:4]`ã€`Q_offset[3:4]`ï¼›
          >
          >ç¬¬2ä¸ªå³çŸ©é˜µ`W[2,:,:]`ï¼Œå¯¹åº”ç´¢å¼•ä½ç½®[4,4)çš„token`x[4:4]`ï¼ˆå…±4-4=0ä¸ªtokenï¼‰ï¼Œå¯¹åº”`x_scale[4:4]`ã€`w_scale[2]`ã€`bias[2]`ã€`offset[2] `ã€`Q[4:4]`ã€`Q_scale[4:4]`ã€`Q_offset[4:4]`ï¼›
          >
          >ç¬¬3ä¸ªå³çŸ©é˜µ`W[3,:,:]`ï¼Œå¯¹åº”ç´¢å¼•ä½ç½®[4,6)çš„token`x[4:6]`ï¼ˆå…±6-4=2ä¸ªtokenï¼‰ï¼Œå¯¹åº”`x_scale[4:6]`ã€`w_scale[3]`ã€`bias[3]`ã€`offset[3] `ã€`Q[4:6]`ã€`Q_scale[4:6]`ã€`Q_offset[4:6]`ï¼›
          >
          >æ³¨ï¼šgrouplistä¸­æœªæŒ‡å®šçš„éƒ¨åˆ†å°†ä¸ä¼šå‚ä¸æ›´æ–°ã€‚
          >ä¾‹å¦‚å½“groupList=[12,14,18]ã€GroupListType=cumsumï¼ŒXçš„shapeä¸º[30ï¼Œ:]æ—¶ã€‚
          >
          >åˆ™ç¬¬ä¸€ä¸ªè¾“å‡ºQçš„shapeä¸º[30ï¼Œ:]ï¼Œå…¶ä¸­Q[18:ï¼Œï¼š]çš„éƒ¨åˆ†ä¸ä¼šè¿›è¡Œæ›´æ–°å’Œåˆå§‹åŒ–ï¼Œå…¶ä¸­æ•°æ®ä¸ºæ˜¾å­˜ç©ºé—´ç”³è¯·æ—¶çš„åŸæ•°æ®ã€‚
          >
          >åŒç†ï¼Œç¬¬äºŒä¸ªè¾“å‡ºQçš„shapeä¸º[30]ï¼Œå…¶ä¸­Q\_scale[18:]çš„éƒ¨åˆ†ä¸ä¼šè¿›è¡Œæ›´æ–°æˆ–åˆå§‹åŒ–ï¼Œå…¶ä¸­æ•°æ®ä¸ºæ˜¾å­˜ç©ºé—´ç”³è¯·æ—¶çš„åŸæ•°æ®ã€‚
          >
          >å³è¾“å‡ºçš„Q[:grouplist[-1],:]å’ŒQ\_scale[:grouplist[-1]]ä¸ºæœ‰æ•ˆæ•°æ®éƒ¨åˆ†ã€‚

        - 2.æ ¹æ®åˆ†ç»„ç¡®å®šçš„å…¥å‚è¿›è¡Œå¦‚ä¸‹è®¡ç®—ï¼š

          $C_{i} = (X_{i}\cdot W_{i} )\odot x\_scale_{i\ BroadCast} \odot w\_scale_{i\ BroadCast}$

          $C_{i,act}, gate_{i} = split(C_{i})$

          $S_{i}=Swish(C_{i,act})\odot gate_{i}$  &nbsp;&nbsp;å…¶ä¸­$Swish(x)=\frac{x}{1+e^{-x}}$

        - 3.é‡åŒ–è¾“å‡ºç»“æœ

          $Q\_scale_{i} = \frac{max(|S_{i}|)}{127}$

          $Q_{i} = \left\lfloor \frac{S_{i}}{Q\_scale_{i}} \right\rceil$
    </details>
    <details>
    <summary>MSDåœºæ™¯A8W4ï¼ˆAæŒ‡æ¿€æ´»çŸ©é˜µï¼ŒWæŒ‡æƒé‡çŸ©é˜µï¼Œ8æŒ‡INT8æ•°æ®ç±»å‹ï¼Œ4æŒ‡INT4æ•°æ®ç±»å‹ï¼‰ï¼š</summary>
    <a id="MSDåœºæ™¯A8W4"></a>
    
      - **å®šä¹‰**ï¼š
        * **â‹…** è¡¨ç¤ºçŸ©é˜µä¹˜æ³•ã€‚
        * **âŠ™** è¡¨ç¤ºé€å…ƒç´ ä¹˜æ³•ã€‚
        * $\left \lfloor x\right \rceil$ è¡¨ç¤ºå°†xå››èˆäº”å…¥åˆ°æœ€è¿‘çš„æ•´æ•°ã€‚
        * $\mathbb{Z_8} = \{ x \in \mathbb{Z} | âˆ’128â‰¤xâ‰¤127 \}$
        * $\mathbb{Z_4} = \{ x \in \mathbb{Z} | âˆ’8â‰¤xâ‰¤7 \}$
        * $\mathbb{Z_{32}} = \{ x \in \mathbb{Z} | -2147483648â‰¤xâ‰¤2147483647 \}$
      - **è¾“å…¥**ï¼š
        * $Xâˆˆ\mathbb{Z_8}^{M \times K}$ï¼šæ¿€æ´»çŸ©é˜µï¼ˆå·¦çŸ©é˜µï¼‰ï¼ŒMæ˜¯æ€»tokenæ•°ï¼ŒKæ˜¯ç‰¹å¾ç»´åº¦ã€‚
        * $Wâˆˆ\mathbb{Z_4}^{E \times K \times N}$ï¼šåˆ†ç»„æƒé‡çŸ©é˜µï¼ˆå³çŸ©é˜µï¼‰ï¼ŒEæ˜¯ä¸“å®¶ä¸ªæ•°ï¼ŒKæ˜¯ç‰¹å¾ç»´åº¦ï¼ŒNæ˜¯è¾“å‡ºç»´åº¦ã€‚
        * $biasâˆˆ\mathbb{R}^{E \times N}$ï¼šè®¡ç®—çŸ©é˜µä¹˜æ—¶çš„è¾…åŠ©çŸ©é˜µï¼ˆç”Ÿæˆè¾…åŠ©çŸ©é˜µçš„è®¡ç®—è¿‡ç¨‹è§ä¸‹æ–‡ï¼‰ã€‚
        * $w\_scaleâˆˆ\mathbb{R}^{E \times K\_group\_num \times N}$ï¼šåˆ†ç»„æƒé‡çŸ©é˜µï¼ˆå³çŸ©é˜µï¼‰çš„é€é€šé“ç¼©æ”¾å› å­ï¼ŒEæ˜¯ä¸“å®¶ä¸ªæ•°ï¼ŒK\_group\_num æ˜¯åœ¨Kè½´ç»´ åº¦ä¸Šçš„åˆ†ç»„æ•°ï¼ŒNæ˜¯è¾“å‡ºç»´åº¦ã€‚
        * $x\_scaleâˆˆ\mathbb{R}^{M}$ï¼šæ¿€æ´»çŸ©é˜µï¼ˆå·¦çŸ©é˜µï¼‰çš„é€tokenç¼©æ”¾å› å­ï¼ŒMæ˜¯æ€»tokenæ•°ã€‚
        * $grouplistâˆˆ\mathbb{N}^{E}$ï¼šcumsumæˆ–countçš„åˆ†ç»„ç´¢å¼•åˆ—è¡¨ã€‚
      - **è¾“å‡º**ï¼š
        * $Qâˆˆ\mathbb{Z_8}^{M \times N / 2}$ï¼šé‡åŒ–åçš„è¾“å‡ºçŸ©é˜µã€‚
        * $Q\_scaleâˆˆ\mathbb{R}^{M}$ï¼šé‡åŒ–ç¼©æ”¾å› å­ã€‚
      - **è®¡ç®—è¿‡ç¨‹**
        - 1.æ ¹æ®groupList[i]ç¡®å®šå½“å‰åˆ†ç»„çš„tokenï¼Œ$i \in [0,Len(groupList)]$ã€‚
          - åˆ†ç»„é€»è¾‘ä¸A8W8ç›¸åŒã€‚
        - 2.ç”Ÿæˆè¾…åŠ©çŸ©é˜µï¼ˆbiasï¼‰çš„è®¡ç®—è¿‡ç¨‹ï¼ˆè¯·æ³¨æ„biaséƒ¨åˆ†è®¡ç®—ä¸ºç¦»çº¿ç”Ÿæˆä½œä¸ºè¾“å…¥ï¼Œå¹¶éç®—å­å†…éƒ¨å®Œæˆï¼‰ï¼š
          - å½“ä¸ºper-channelé‡åŒ–ï¼ˆ$w\_scale$ä¸º2ç»´ï¼‰ï¼š

            $bias_{i} = 8 Ã— weightScale Ã— Î£_{k=0}^{K-1} weight[:,k,:]$

          - å½“ä¸ºper-groupé‡åŒ–ï¼ˆ$w\_scale$ä¸º3ç»´ï¼‰ï¼š

            $bias_{i} = 8 Ã— Î£_{k=0}^{K-1} (weight[:,k,:] Ã— weightScale[:, âŒŠk/num\_per\_groupâŒ‹, :])$

            æ³¨ï¼š$num\_per\_group = K // K\_group\_num$

        - 3.æ ¹æ®åˆ†ç»„ç¡®å®šçš„å…¥å‚è¿›è¡Œå¦‚ä¸‹è®¡ç®—ï¼š

          - 3.1.å°†å·¦çŸ©é˜µ$\mathbb{Z_8}$ï¼Œè½¬å˜ä¸ºé«˜ä½ä½ ä¸¤éƒ¨åˆ†çš„$\mathbb{Z_4}$
            $X\_high\_4bits_{i} = \lfloor \frac{X_{i}}{16} \rfloor$
            $X\_low\_4bits_{i} = X_{i} \& 0x0f - 8$
          - 3.2.åšçŸ©é˜µä¹˜æ—¶ï¼Œä½¿èƒ½per-channelæˆ–per-groupé‡åŒ–
            per-channelï¼š

            $C\_high_{i} = (X\_high\_4bits_{i} \cdot W_{i}) \odot w\_scale_{i}$

            $C\_low_{i} = (X\_low\_4bits_{i} \cdot W_{i}) \odot w\_scale_{i}$

            per-groupï¼š

            $C\_high_{i} = \\ Î£_{k=0}^{K-1}((X\_high\_4bits_{i}[:, k * num\_per\_group : (k+1) * num\_per\_group] \cdot W_{i}[k *   num\_per\_group : (k+1) * num\_per\_group, :]) \odot w\_scale_{i}[k, :] )$

            $C\_low_{i} = \\ Î£_{k=0}^{K-1}((X\_low\_4bits_{i}[:, k * num\_per\_group : (k+1) * num\_per\_group] \cdot W_{i}[k *   num\_per\_group : (k+1) * num\_per\_group, :]) \odot w\_scale_{i}[k, :] )$

          - 3.3.å°†é«˜ä½ä½çš„çŸ©é˜µä¹˜ç»“æœè¿˜åŸä¸ºæ•´ä½“çš„ç»“æœ

            $C_{i} = (C\_high_{i} * 16 + C\_low_{i} + bias_{i}) \odot x\_scale_{i}$

            $C_{i,act}, gate_{i} = split(C_{i})$

            $S_{i}=Swish(C_{i,act})\odot gate_{i}$  &nbsp;&nbsp; å…¶ä¸­$Swish(x)=\frac{x}{1+e^{-x}}$

        - 3.é‡åŒ–è¾“å‡ºç»“æœ

          $Q\_scale_{i} = \frac{max(|S_{i}|)}{127}$

          $Q_{i} = \left\lfloor \frac{S_{i}}{Q\_scale_{i}} \right\rceil$
    </details>

  - <term>æ˜‡è…¾910_95 AIå¤„ç†å™¨</term>ï¼š
    <details>
    <summary>MXé‡åŒ–åœºæ™¯ï¼š</summary>

      - **å®šä¹‰**ï¼š

        * **â‹…** è¡¨ç¤ºçŸ©é˜µä¹˜æ³•ã€‚
        * **âŠ™** è¡¨ç¤ºé€å…ƒç´ ä¹˜æ³•ã€‚
      - **è®¡ç®—è¿‡ç¨‹**
        - 1.æ ¹æ®groupList[i]ç¡®å®šå½“å‰åˆ†ç»„çš„ token ï¼Œ$i \in [0,Len(groupList)]$

        - 2.æ ¹æ®åˆ†ç»„ç¡®å®šçš„å…¥å‚è¿›è¡Œå¦‚ä¸‹è®¡ç®—ï¼š

          $C_{i} = (X_{i}\cdot W_{i} )\odot xScale_{i\ BroadCast} \odot wScale_{i\ BroadCast}$

          $C_{i,act}, gate_{i} = split(C_{i})$

          $S_{i}=Swish(C_{i,act})\odot gate_{i}$ï¼Œå…¶ä¸­$Swish(x)=\frac{x}{1+e^{-x}}$

        - 3.é‡åŒ–è¾“å‡ºç»“æœ

          $shared\_exp = \left\lfloor \log_2(max_i(|S_i|)) \right\rceil - emax$

          $QScale = 2 ^ {shared\_exp}$

          $Q_i = quantize\_to\_element\_format(S_i/Qscale), \space i\space from\space 1\space to\space blocksize$
          - $emax$: å¯¹åº”æ•°æ®ç±»å‹çš„æœ€å¤§æ­£åˆ™æ•°çš„æŒ‡æ•°ä½ã€‚

            |   DataType    | emax |
            | :-----------: | :--: |
            | FLOAT8_E4M3FN |  8   |
            |  FLOAT8_E5M2  |  15  |
            |  FLOAT4_E1M2  |  1   |
            |  FLOAT4_E2M1  |  2   |
          - $blocksize$ï¼šæŒ‡æ¯æ¬¡é‡åŒ–çš„å…ƒç´ ä¸ªæ•°ï¼Œä»…æ”¯æŒ32ã€‚
    </details>

## å‡½æ•°åŸå‹

æ¯ä¸ªç®—å­åˆ†ä¸º[ä¸¤æ®µå¼æ¥å£](../../../docs/zh/context/ä¸¤æ®µå¼æ¥å£.md)ï¼Œå¿…é¡»å…ˆè°ƒç”¨â€œaclnnGroupedMatmulSwigluQuantV2GetWorkspaceSizeâ€æ¥å£è·å–è®¡ç®—æ‰€éœ€workspaceå¤§å°ä»¥åŠåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹çš„æ‰§è¡Œå™¨ï¼Œå†è°ƒç”¨â€œaclnnGroupedMatmulSwigluQuantV2â€æ¥å£æ‰§è¡Œè®¡ç®—ã€‚

```Cpp
aclnnStatus aclnnGroupedMatmulSwigluQuantV2GetWorkspaceSize(
    const aclTensor     *x, 
    const aclTensorList *weight, 
    const aclTensorList *weightScale,
    const aclTensorList *weightAsistMatrix, 
    const aclTensor     *bias, 
    const aclTensor     *xScale, 
    const aclTensor     *smoothScale, 
    const aclTensor     *groupList, 
    int64_t              dequantMode, 
    int64_t              dequantDtype, 
    int64_t              quantMode,  
    int64_t              groupListType, 
    const aclIntArray   *tuningConfig, 
    aclTensor           *output, 
    aclTensor           *outputScale, 
    uint64_t            *workspaceSize, 
    aclOpExecutor       **executor)
```
```Cpp
aclnnStatus aclnnGroupedMatmulSwigluQuantV2(
    void          *workspace, 
    uint64_t       workspaceSize, 
    aclOpExecutor *executor, 
    aclrtStream    stream)
```

## aclnnGroupedMatmulSwigluQuantV2GetWorkspaceSize

  - **å‚æ•°è¯´æ˜ï¼š**
    <table style="undefined;table-layout: fixed;width: 1567px"><colgroup>
    <col style="width: 170px">
    <col style="width: 120px">
    <col style="width: 300px">
    <col style="width: 330px">
    <col style="width: 212px">
    <col style="width: 100px">
    <col style="width: 190px">
    <col style="width: 145px">
    </colgroup>
    <thead>
      <tr>
        <th>å‚æ•°å</th>
        <th style="white-space: nowrap">è¾“å…¥/è¾“å‡º</th>
        <th>æè¿°</th>
        <th>ä½¿ç”¨è¯´æ˜</th>
        <th>æ•°æ®ç±»å‹</th>
        <th><a href="../../../docs/zh/context/æ•°æ®æ ¼å¼.md" target="_blank">æ•°æ®æ ¼å¼</a></th>
        <th style="white-space: nowrap">ç»´åº¦(shape)</th>
        <th><a href="../../../docs/zh/context/éè¿ç»­çš„Tensor.md" target="_blank">éè¿ç»­çš„Tensor</a></th>
      </tr>
    </thead>
    <tbody>
      <tr>
        <td>x</td>
        <td rowspan="1">è¾“å…¥</td>
        <td>è¡¨ç¤ºå·¦çŸ©é˜µï¼ŒDeviceä¾§çš„aclTensorï¼Œå¯¹åº”å…¬å¼ä¸­çš„Xã€‚</td>
        <td><ul><li>ä½¿ç”¨INT8æ•°æ®ç±»å‹æ—¶ï¼ŒKå¿…é¡»å°äº65536ã€‚</li></ul></td>
        <td>FLOAT8_E4M3FNã€FLOAT8_E5M2ã€FLOAT4_E1M2ã€FLOAT4_E2M1ã€INT8</td>
        <td>ND</td>
        <td>2ï¼Œå½¢å¦‚(M, K)</td>
        <td>âˆš</td>
      </tr>
      <tr>
        <td>weight</td>
        <td rowspan="1">è¾“å…¥</td>
        <td>è¡¨ç¤ºæƒé‡çŸ©é˜µï¼ŒDeviceä¾§çš„aclTensorListï¼Œå¯¹åº”å…¬å¼ä¸­çš„Wã€‚</td>
        <td><ul>
          <li>INT32ä¸ºé€‚é…ç”¨é€”ï¼Œå®é™…1ä¸ªINT32ä¼šè¢«è§£é‡Šä¸º8ä¸ªINT4æ•°æ®ã€‚</li>
          <li>NDæ•°æ®æ ¼å¼ä»…A8W4ã€MXFP8ã€MXFP4åœºæ™¯æ”¯æŒã€‚</li>
          <li>ç›®å‰ä»…æ”¯æŒtensor listé•¿åº¦ä¸º1ã€‚</li>
        </ul></td>
        <td>FLOAT8_E4M3FNã€FLOAT8_E5M2ã€FLOAT4_E1M2ã€FLOAT4_E2M1ã€INT8ã€INT4ã€INT32</td>
        <td>NDã€FRACTAL_NZ</td>
        <td>3ï¼Œweightéè½¬ç½®shapeå½¢å¦‚{(E, K, N)}ï¼Œweightè½¬ç½®shapeå½¢å¦‚{(E, N, K)}</td>
        <td>âˆš</td>
      </tr>
      <tr>
        <td>weightScale</td>
        <td rowspan="1">è¾“å…¥</td>
        <td>è¡¨ç¤ºå³çŸ©é˜µçš„é‡åŒ–å› å­ï¼ŒDeviceä¾§çš„aclTensorListï¼Œå…¬å¼ä¸­çš„wScaleã€‚</td>
        <td><ul>
          <li>é¦–è½´é•¿åº¦éœ€ä¸weightçš„é¦–è½´ç»´åº¦ç›¸ç­‰ï¼Œå°¾è½´é•¿åº¦éœ€è¦ä¸weightè¿˜åŸä¸ºNDæ ¼å¼çš„å°¾è½´ç›¸åŒã€‚</li>
          <li>A8W4åœºæ™¯ï¼šshapeæ”¯æŒ2æˆ–3ç»´ï¼Œæ•°æ®ç±»å‹æ”¯æŒUINT64ã€‚</li>
          <li>A8W8åœºæ™¯ï¼šshapeæ”¯æŒ2ç»´ï¼Œæ•°æ®ç±»å‹æ”¯æŒFLOATã€FLOAT16ã€BFLOAT16ã€‚</li>
          <li>MXé‡åŒ–åœºæ™¯ï¼šshapeæ”¯æŒ4ç»´ï¼Œæ•°æ®ç±»å‹æ”¯æŒFLOAT8_E8M0ã€‚</li>
          <li>ç›®å‰ä»…æ”¯æŒtensor listé•¿åº¦ä¸º1ã€‚</li>
        </ul></td>
        <td>FLOAT8_E8M0ã€UINT64ã€FLOATã€FLOAT16ã€BFLOAT16</td>
        <td>ND</td>
        <td>2-4ï¼ŒMXé‡åŒ–åœºæ™¯ï¼šweightScaleéè½¬ç½®shapeå½¢å¦‚{(E, ceil(K / 64), N, 2)}ï¼ŒweightScaleè½¬ç½®shapeå½¢å¦‚{(E, N, ceil(K / 64), 2)}</td>
        <td>âˆš</td>
      </tr>
      <tr>
        <td>weightAssistMatrix</td>
        <td rowspan="1">å¯é€‰è¾“å…¥</td>
        <td>è¡¨ç¤ºè®¡ç®—çŸ©é˜µä¹˜æ—¶çš„è¾…åŠ©çŸ©é˜µï¼ŒDeviceä¾§çš„aclTensorListï¼Œå…¬å¼ä¸­çš„biasã€‚</td>
        <td><ul>
          <li>ä»…A8W4åœºæ™¯ç”Ÿæ•ˆï¼Œå…¶ä»–åœºæ™¯éœ€ä¼ ç©ºæŒ‡é’ˆã€‚</li>
          <li>é¦–è½´é•¿åº¦éœ€ä¸weightçš„é¦–è½´ç»´åº¦ç›¸ç­‰ï¼Œå°¾è½´é•¿åº¦éœ€è¦ä¸weightè¿˜åŸä¸ºNDæ ¼å¼çš„å°¾è½´ç›¸åŒã€‚</li>
        </ul></td>
        <td>FP32</td>
        <td>-</td>
        <td>2</td>
        <td>-</td>
      </tr>
      <tr>
        <td>bias</td>
        <td rowspan="1">å¯é€‰è¾“å…¥</td>
        <td>è¡¨ç¤ºçŸ©é˜µä¹˜è®¡ç®—çš„åç§»å€¼ï¼ŒDeviceä¾§çš„aclTensorã€‚</td>
        <td><ul>
          <li>é¢„ç•™è¾“å…¥ï¼Œæš‚ä¸æ”¯æŒï¼Œéœ€è¦ä¼ ç©ºæŒ‡é’ˆã€‚</li>
        </ul></td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td>xScale</td>
        <td rowspan="1">è¾“å…¥</td>
        <td>è¡¨ç¤ºå·¦çŸ©é˜µçš„çš„é‡åŒ–å› å­ï¼ŒDeviceä¾§çš„aclTensorï¼Œå…¬å¼ä¸­çš„xScaleã€‚</td>
        <td><ul>
          <li>FLOATæ•°æ®ç±»å‹ï¼šshapeæ”¯æŒ1ç»´ï¼Œé•¿åº¦éœ€ä¸xçš„é¦–è½´ç»´åº¦ç›¸ç­‰ã€‚</li>
          <li>FLOAT8_E8M0æ•°æ®ç±»å‹ï¼šshapeæ”¯æŒ3ç»´ã€‚</li>
        </ul></td>
        <td>FLOAT8_E8M0ã€FLOAT</td>
        <td>ND</td>
        <td>1ã€3ï¼Œå½¢å¦‚ï¼ˆMï¼‰ã€(M, ceil(K / 64), 2)</td>
        <td>âˆš</td>
      </tr>
      <tr>
        <td>smoothScale</td>
        <td rowspan="1">å¯é€‰è¾“å…¥</td>
        <td>è¡¨ç¤ºå·¦çŸ©é˜µçš„çš„é‡åŒ–å› å­ï¼ŒDeviceä¾§çš„aclTensorã€‚</td>
        <td><ul>
          <li>é¢„ç•™è¾“å…¥ï¼Œæš‚ä¸æ”¯æŒï¼Œéœ€è¦ä¼ ç©ºæŒ‡é’ˆã€‚</li>
        </ul></td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td>groupList</td>
        <td rowspan="1">è¾“å…¥</td>
        <td>è¡¨ç¤ºæ¯ä¸ªåˆ†ç»„å‚ä¸è®¡ç®—çš„Tokenä¸ªæ•°ï¼ŒDeviceä¾§çš„aclTensorï¼Œå…¬å¼ä¸­çš„grouplistã€‚</td>
        <td><ul>
          <li>é•¿åº¦éœ€ä¸weightçš„é¦–è½´ç»´åº¦ç›¸ç­‰ã€‚</li>
          <li>grouplistä¸­çš„æœ€åä¸€ä¸ªå€¼çº¦æŸäº†è¾“å‡ºæ•°æ®çš„æœ‰æ•ˆéƒ¨åˆ†ï¼Œè¯¦è§åŠŸèƒ½è¯´æ˜ä¸­çš„è®¡ç®—è¿‡ç¨‹éƒ¨åˆ†ã€‚</li>
        </ul></td>
        <td>INT64</td>
        <td>ND</td>
        <td>1ï¼Œå½¢å¦‚(E,)</td>
        <td>âˆš</td>
      </tr>
      <tr>
        <td>dequantMode</td>
        <td rowspan="1">è¾“å…¥</td>
        <td>è¡¨ç¤ºåé‡åŒ–è®¡ç®—ç±»å‹ï¼Œç”¨äºç¡®å®šæ¿€æ´»çŸ©é˜µä¸æƒé‡çŸ©é˜µçš„åé‡åŒ–æ–¹å¼ã€‚</td>
        <td><ul>
          <li>0è¡¨ç¤ºæ¿€æ´»çŸ©é˜µper-tokenï¼Œæƒé‡çŸ©é˜µper-channelã€‚</li>
          <li>1è¡¨ç¤ºæ¿€æ´»çŸ©é˜µper-tokenï¼Œæƒé‡çŸ©é˜µper-groupã€‚</li>
          <li>2è¡¨ç¤ºæ¿€æ´»çŸ©é˜µmxï¼Œæƒé‡çŸ©é˜µmxã€‚</li>
        </ul></td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td>dequantDtype</td>
        <td rowspan="1">è¾“å…¥</td>
        <td>è¡¨ç¤ºä¸­é—´GroupedMatmulçš„ç»“æœæ•°æ®ç±»å‹ã€‚</td>
        <td><ul>
          <li>0è¡¨ç¤ºDT_FLOATã€‚</li>
          <li>1è¡¨ç¤ºFLOAT16ã€‚</li>
          <li>27è¡¨ç¤ºBF16ã€‚</li>
          <li>28è¡¨ç¤ºUNDEFINEDã€‚</li>
        </ui></td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td>quantMode</td>
        <td rowspan="1">è¾“å…¥</td>
        <td>è¡¨ç¤ºé‡åŒ–è®¡ç®—ç±»å‹ï¼Œç”¨äºç¡®å®šswigluç»“æœçš„é‡åŒ–æ¨¡å¼ã€‚</td>
        <td><ul>
          <li>0è¡¨ç¤ºper-tokenã€‚</li>
          <li>1è¡¨ç¤ºper-groupã€‚</li>
          <li>2è¡¨ç¤ºmxã€‚</li>
        </td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td>groupListType</td>
        <td rowspan="1">è¾“å…¥</td>
        <td>è¡¨ç¤ºåˆ†ç»„çš„è§£é‡Šæ–¹å¼ï¼Œç”¨äºç¡®å®šgroupListçš„è¯­ä¹‰ã€‚</td>
        <td><ul><li>0è¡¨ç¤ºcumsumæ¨¡å¼ï¼ŒgroupListä¸­çš„æ¯ä¸ªå…ƒç´ ä»£è¡¨å½“å‰åˆ†ç»„çš„ç´¯è®¡é•¿åº¦ã€‚</li><li>1è¡¨ç¤ºcountæ¨¡å¼ï¼ŒgroupListä¸­çš„æ¯ä¸ªå…ƒç´ ä»£è¡¨è¯¥åˆ†ç»„åŒ…å«å¤šå°‘å…ƒç´ ã€‚</li></td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td>tuningConfig</td>
        <td rowspan="1">å¯é€‰è¾“å…¥</td>
        <td>ç”¨äºç®—å­é¢„ä¼°M/Eçš„å¤§å°ï¼Œèµ°ä¸åŒçš„ç®—å­æ¨¡æ¿ï¼Œä»¥é€‚é…ä¸ä¸åŒåœºæ™¯æ€§èƒ½è¦æ±‚ã€‚</td>
        <td><ul><li>é¢„ç•™è¾“å…¥ï¼Œæš‚ä¸æ”¯æŒï¼Œéœ€è¦ä¼ ç©ºæŒ‡é’ˆã€‚</li></ul></td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td>output</td>
        <td rowspan="1">è¾“å‡º</td>
        <td>è¡¨ç¤ºè¾“å‡ºçš„é‡åŒ–ç»“æœï¼ŒDeviceä¾§çš„aclTensorï¼Œå…¬å¼ä¸­çš„Qã€‚</td>
        <td>-</td>
        <td>FLOAT8_E4M3FNã€FLOAT8_E5M2ã€FLOAT4_E1M2ã€FLOAT4_E2M1ã€INT8</td>
        <td>ND</td>
        <td>2ï¼Œå½¢å¦‚(M, N / 2)</td>
        <td>âˆš</td>
      </tr>
      <tr>
        <td>outputScale</td>
        <td rowspan="1">è¾“å‡º</td>
        <td>è¡¨ç¤ºè¾“å‡ºçš„é‡åŒ–å› å­ï¼ŒDeviceä¾§çš„aclTensorï¼Œå…¬å¼ä¸­çš„QScaleã€‚</td>
        <td>
          <ul>
            <li>FLOATæ•°æ®ç±»å‹ï¼Œshapeæ”¯æŒ1ç»´ã€‚</li>
            <li>FLOAT8_E8M0æ•°æ®ç±»å‹ï¼Œshapeæ”¯æŒ3ç»´ã€‚</li>
          </ul>
        </td>
        <td>FLOAT8_E8M0ã€FLOAT</td>
        <td>ND</td>
        <td>1ã€3ï¼Œå½¢å¦‚ï¼ˆMï¼‰ã€(M, ceil((N / 2) / 64), 2)</td>
        <td>âˆš</td>
      </tr>
      <tr>
        <td>workspaceSize</td>
        <td rowspan="1">è¾“å‡º</td>
        <td>è¿”å›éœ€è¦åœ¨Deviceä¾§ç”³è¯·çš„workspaceå¤§å°ã€‚</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
      <tr>
        <td>executor</td>
        <td rowspan="1">è¾“å‡º</td>
        <td>è¿”å›opæ‰§è¡Œå™¨ï¼ŒåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹ã€‚</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
        <td>-</td>
      </tr>
    </tbody>
    </table>

    - <term>Atlas A3 è®­ç»ƒç³»åˆ—äº§å“/Atlas A3 æ¨ç†ç³»åˆ—äº§å“</term>ã€<term>Atlas A2 è®­ç»ƒç³»åˆ—äº§å“/Atlas 800I A2 æ¨ç†äº§å“/A200I A2 Box å¼‚æ„ç»„ä»¶</term>ï¼šä¸æ”¯æŒFLOAT8é‡åŒ–æ•°æ®ç±»å‹ã€æ”¯æŒå…¶ä»–æ•°æ®ç±»å‹ï¼Œä¸æ”¯æŒweightè½¬ç½®ã€ä¸æ”¯æŒdequantDtypeå‚æ•°ã€‚
      - A8W4/A8W8åœºæ™¯ï¼Œä¸æ”¯æŒNè½´é•¿åº¦è¶…è¿‡10240ã€‚
      - A8W8åœºæ™¯ï¼Œä¸æ”¯æŒxçš„å°¾è½´é•¿åº¦å¤§äºç­‰äº65536ã€‚
      - A8W4åœºæ™¯ï¼Œä¸æ”¯æŒxçš„å°¾è½´é•¿åº¦å¤§äºç­‰äº20000ã€‚
    - <term>æ˜‡è…¾910_95 AIå¤„ç†å™¨</term>ï¼š
      - ä»…æ”¯æŒFLOAT8ã€FLOAT4é‡åŒ–æ•°æ®ç±»å‹ï¼Œä¸æ”¯æŒå…¶ä»–æ•°æ®ç±»å‹ï¼Œæ”¯æŒweightè½¬ç½®ã€‚
      - æ”¯æŒdequantModeå‚æ•°ï¼šé»˜è®¤å€¼ä¸º0ï¼Œå½“å‰ä»…æ”¯æŒä¼ å…¥2ã€‚
      - æ”¯æŒdequantDtypeå‚æ•°ï¼šå½“å‰ä»…æ”¯æŒä¼ å…¥é»˜è®¤å€¼0ã€‚
      - æ”¯æŒquantDtypeå‚æ•°ï¼šé»˜è®¤å€¼ä¸º0ï¼Œå½“å‰ä»…æ”¯æŒä¼ å…¥2ã€‚

- **è¿”å›å€¼ï¼š**
  
  aclnnStatusï¼šè¿”å›çŠ¶æ€ç ï¼Œå…·ä½“å‚è§[aclnnè¿”å›ç ](../../../docs/zh/context/aclnnè¿”å›ç .md)ã€‚

  ç¬¬ä¸€æ®µæ¥å£å®Œæˆå…¥å‚æ ¡éªŒï¼Œå‡ºç°ä»¥ä¸‹åœºæ™¯æ—¶æŠ¥é”™ï¼š
  <table style="undefined;table-layout: fixed;width: 1030px"><colgroup>
  <col style="width: 250px">
  <col style="width: 130px">
  <col style="width: 650px">
  </colgroup>
  <thead>
    <tr>
      <th>è¿”å›ç </th>
      <th>é”™è¯¯ç </th>
      <th>æè¿°</th>
    </tr></thead>
  <tbody>
    <tr>
      <td>ACLNN_ERR_PARAM_NULLPTR</td>
      <td>161001</td>
      <td>å‚æ•°xã€weightã€weightScaleã€xScaleã€groupListã€outputã€outputScaleæ˜¯ç©ºæŒ‡é’ˆã€‚</td>
    </tr>
    <tr>
      <td rowspan="9">ACLNN_ERR_PARAM_INVALID</td>
      <td rowspan="9">161002</td>
      <td>ä¼ å…¥çš„xã€weightã€weightScaleã€xScaleã€groupListã€outputã€outputScaleçš„æ•°æ®ç»´åº¦ä¸æ»¡è¶³çº¦æŸã€‚</td>
    </tr>
    <tr>
      <td>ä¼ å…¥çš„xã€weightã€weightScaleã€xScaleã€groupListã€outputã€outputScaleæ•°æ®çš„shapeä¸æ»¡è¶³çº¦æŸæ¡ä»¶ã€‚</td>
    </tr>
    <tr>
      <td>ä¼ å…¥çš„xã€weightã€weightScaleã€xScaleã€groupListã€outputã€outputScaleæ•°æ®çš„formatä¸æ»¡è¶³çº¦æŸæ¡ä»¶ã€‚</td>
    </tr>
    <tr>
      <td>ä¼ å…¥çš„weightã€weightScaleçš„tensor listé•¿åº¦ä¸ä¸º1ã€‚</td>
    </tr>
    <tr>
      <td>ä¼ å…¥çš„xã€xScaleä¸ºç©ºtensorï¼Œä¼ å…¥çš„weightã€weightScaleä¸ºç©ºtensorListã€‚</td>
    </tr>
    <tr>
      <td>groupListçš„å…ƒç´ ä¸ªæ•°å¤§äºweightçš„é¦–è½´é•¿åº¦ã€‚</td>
    </tr>
    <tr>
      <td>A8W4ã€A8W8åœºæ™¯ï¼ŒNè½´å–å€¼ä¸ç¬¦åˆçº¦æŸã€‚</td>
    </tr>
    <tr>
      <td>A8W4ã€A8W8åœºæ™¯ï¼Œxçš„å°¾è½´é•¿åº¦ä¸ç¬¦åˆçº¦æŸã€‚</td>
    </tr>
    <tr>
      <td>MXé‡åŒ–åœºæ™¯<ul>
      <li>Nä¸ä¸ºå¶æ•°ã€‚</li>
      <li>ä¼ å…¥çš„dequantModeã€quantModeä¸ä¸º2ï¼ŒdequantDtypeä¸ä¸º0ã€‚</li>
      <li>ä¼ å…¥çš„biasã€weightAssistMatrixã€smoothScaleã€tuningConfigä¸ä¸ºç©ºæŒ‡é’ˆã€‚</li>
      </ul></td>
    </tr>
  </tbody>
  </table>

## aclnnGroupedMatmulSwigluQuantV2

- **å‚æ•°è¯´æ˜ï¼š**
  <table>
    <thead>
      <tr><th>å‚æ•°å</th><th>è¾“å…¥/è¾“å‡º</th><th>æè¿°</th></tr>
    </thead>
    <tbody>
      <tr><td>workspace</td><td>è¾“å…¥</td><td>åœ¨Deviceä¾§ç”³è¯·çš„workspaceå†…å­˜åœ°å€ã€‚</td></tr>
      <tr><td>workspaceSize</td><td>è¾“å…¥</td><td>åœ¨Deviceä¾§ç”³è¯·çš„workspaceå¤§å°ï¼Œç”±ç¬¬ä¸€æ®µæ¥å£aclnnGroupedMatmulSwigluQuantV2GetWorkspaceSizeè·å–ã€‚</td></tr>
      <tr><td>executor</td><td>è¾“å…¥</td><td>opæ‰§è¡Œå™¨ï¼ŒåŒ…å«äº†ç®—å­è®¡ç®—æµç¨‹ã€‚</td></tr>
      <tr><td>stream</td><td>è¾“å…¥</td><td>æŒ‡å®šæ‰§è¡Œä»»åŠ¡çš„Streamã€‚</td></tr>
    </tbody>
  </table>

- **è¿”å›å€¼ï¼š**

  è¿”å›aclnnStatusçŠ¶æ€ç ï¼Œå…·ä½“å‚è§[aclnnè¿”å›ç ](../../../docs/zh/context/aclnnè¿”å›ç .md)ã€‚

## çº¦æŸè¯´æ˜
  - <term>æ˜‡è…¾910_95 AIå¤„ç†å™¨</term>ï¼š
    - MXé‡åŒ–åœºæ™¯ä¸‹éœ€æ»¡è¶³ä»¥ä¸‹çº¦æŸæ¡ä»¶ï¼š
        - æ•°æ®ç±»å‹éœ€è¦æ»¡è¶³ä¸‹è¡¨ï¼š
        <table style="undefined;table-layout: fixed; width: 1134px"><colgroup>
        <col style="width: 319px">
        <col style="width: 144px">
        <col style="width: 671px">
        </colgroup>
        <thead>
          <tr>
            <th>MXé‡åŒ–åœºæ™¯</th>
            <th>x</th>
            <th>weight</th>
            <th>weightScale</th>
            <th>xScale</th>
            <th>output</th>
            <th>outputScale</th>
          </tr></thead>
        <tbody>
          <tr>
            <td>MXFP8</td>
            <td>FLOAT8_E4M3FNã€FLOAT8_E5M2</td>
            <td>FLOAT8_E4M3FNã€FLOAT8_E5M2</td>
            <td>FLOAT8_E8M0</td>
            <td>FLOAT8_E8M0</td>
            <td>FLOAT8_E4M3FNã€FLOAT8_E5M2</td>
            <td>FLOAT8_E8M0</td>
          </tr>
          <tr>
            <td>MXFP4</td>
            <td>FLOAT4_E1M2ã€FLOAT4_E2M1</td>
            <td>FLOAT4_E1M2ã€FLOAT4_E2M1</td>
            <td>FLOAT8_E8M0</td>
            <td>FLOAT8_E8M0</td>
            <td>FLOAT4_E1M2ã€FLOAT4_E2M1ã€FLOAT8_E4M3FNã€FLOAT8_E5M2</td>
            <td>FLOAT8_E8M0</td>
          </tr>
        </tbody>
        </table>

      - MXé‡åŒ–åœºæ™¯ä¸‹ï¼Œéœ€æ»¡è¶³Nä¸º128å¯¹é½ã€‚
      - MXFP4åœºæ™¯ä¸æ”¯æŒK=2ã€‚
      - MXFP4åœºæ™¯éœ€æ»¡è¶³Kä¸ºå¶æ•°ï¼›å½“outputçš„æ•°æ®ç±»å‹ä¸ºFLOAT4_E1M2ã€FLOAT4_E2M1æ—¶ï¼Œéœ€æ»¡è¶³Nä¸ºå¤§äºç­‰äº4çš„å¶æ•°ã€‚

  - ç¡®å®šæ€§è¯´æ˜ï¼šaclnnGroupedMatmulSwigluQuantV2é»˜è®¤ä¸ºç¡®å®šæ€§å®ç°ã€‚

## è°ƒç”¨ç¤ºä¾‹
ç¤ºä¾‹ä»£ç å¦‚ä¸‹ï¼Œä»…ä¾›å‚è€ƒï¼Œå…·ä½“ç¼–è¯‘å’Œæ‰§è¡Œè¿‡ç¨‹è¯·å‚è€ƒ[ç¼–è¯‘ä¸è¿è¡Œæ ·ä¾‹](../../../docs/zh/context/ç¼–è¯‘ä¸è¿è¡Œæ ·ä¾‹.md)ã€‚
  - <term>Atlas A3 è®­ç»ƒç³»åˆ—äº§å“/Atlas A3 æ¨ç†ç³»åˆ—äº§å“</term>ã€<term>Atlas A2 è®­ç»ƒç³»åˆ—äº§å“/Atlas 800I A2 æ¨ç†äº§å“/A200I A2 Box å¼‚æ„ç»„ä»¶</term>ï¼š
    ```cpp
    #include <iostream>
    #include <vector>
    #include "acl/acl.h"
    #include "aclnnop/aclnn_grouped_matmul_swiglu_quant_weight_nz_v2.h"

    #define CHECK_RET(cond, return_expr)                                                                                   \
        do {                                                                                                               \
            if (!(cond)) {                                                                                                 \
                return_expr;                                                                                               \
            }                                                                                                              \
        } while (0)

    #define LOG_PRINT(message, ...)                                                                                        \
        do {                                                                                                               \
            printf(message, ##__VA_ARGS__);                                                                                \
        } while (0)

    int64_t GetShapeSize(const std::vector<int64_t>& shape) {
        int64_t shapeSize = 1;
        for (auto i : shape) {
            shapeSize *= i;
        }
        return shapeSize;
    }

    int Init(int32_t deviceId, aclrtStream* stream) {
        // å›ºå®šå†™æ³•ï¼Œèµ„æºåˆå§‹åŒ–
        auto ret = aclInit(nullptr);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclInit failed. ERROR: %d\n", ret); return ret);
        ret = aclrtSetDevice(deviceId);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSetDevice failed. ERROR: %d\n", ret); return ret);
        ret = aclrtCreateStream(stream);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtCreateStream failed. ERROR: %d\n", ret); return ret);
        return 0;
    }

    template <typename T>
    int CreateAclTensor(const std::vector<T>& hostData, const std::vector<int64_t>& shape, 
                        void** deviceAddr, aclDataType dataType, aclFormat formatType, aclTensor** tensor) {
        auto size = GetShapeSize(shape) * sizeof(T);
        // è°ƒç”¨aclrtMallocç”³è¯·deviceä¾§å†…å­˜
        auto ret = aclrtMalloc(deviceAddr, size, ACL_MEM_MALLOC_HUGE_FIRST);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMalloc failed. ERROR: %d\n", ret); return ret);
        // è°ƒç”¨aclrtMemcpyå°†hostä¾§æ•°æ®å¤åˆ¶åˆ°deviceä¾§å†…å­˜ä¸Š
        ret = aclrtMemcpy(*deviceAddr, size, hostData.data(), size, ACL_MEMCPY_HOST_TO_DEVICE);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMemcpy failed. ERROR: %d\n", ret); return ret);

        // è®¡ç®—è¿ç»­tensorçš„strides
        std::vector<int64_t> strides(shape.size(), 1);
        for (int64_t i = shape.size() - 2; i >= 0; i--) {
        strides[i] = shape[i + 1] * strides[i + 1];
        }

        // è°ƒç”¨aclCreateTensoræ¥å£åˆ›å»ºaclTensor
        *tensor = aclCreateTensor(shape.data(), shape.size(), dataType, strides.data(), 0, formatType,
                                shape.data(), shape.size(), *deviceAddr);
        return 0;
    }

    template <typename T>
    int CreateAclTensorList(const std::vector<T> &hostData, const std::vector<std::vector<int64_t>> &shapes,
                            void **deviceAddr, aclDataType dataType, aclFormat formatType, aclTensorList **tensor) {
        int size = shapes.size();
        aclTensor* tensors[size];
        for (int i = 0; i < size; i++) {
            int ret = CreateAclTensor<T>(hostData, shapes[i], deviceAddr + i, dataType, formatType, tensors + i);
            CHECK_RET(ret == ACL_SUCCESS, return ret);
        }
        *tensor = aclCreateTensorList(tensors, size);
        return ACL_SUCCESS;
    }

    int main() {
        // 1. ï¼ˆå›ºå®šå†™æ³•ï¼‰device/streamåˆå§‹åŒ–ï¼Œå‚è€ƒacl APIæ‰‹å†Œ
        // æ ¹æ®è‡ªå·±çš„å®é™…deviceå¡«å†™deviceId
        int32_t deviceId = 0;
        aclrtStream stream;
        auto ret = Init(deviceId, &stream);
        // checkæ ¹æ®è‡ªå·±çš„éœ€è¦å¤„ç†
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("Init acl failed. ERROR: %d\n", ret); return ret);

        // 2. æ„é€ è¾“å…¥ä¸è¾“å‡ºï¼Œéœ€è¦æ ¹æ®APIçš„æ¥å£è‡ªå®šä¹‰æ„é€ 
        int64_t E = 4;
        int64_t M = 8192;
        int64_t N = 4096;
        int64_t K = 7168;
        std::vector<int64_t> xShape = {M, K};
        std::vector<std::vector<int64_t>> weightShape = {{E, N / 32 , K / 16, 16, 32}};
        std::vector<std::vector<int64_t>> weightScaleShape = {{E, N}};
        std::vector<int64_t> xScaleShape = {M};
        std::vector<int64_t> groupListShape = {E};
        std::vector<int64_t> outputShape = {M, N / 2};
        std::vector<int64_t> outputScaleShape = {M};

        void* xDeviceAddr = nullptr;
        void* weightDeviceAddr[1];
        void* weightScaleDeviceAddr[1];
        void* xScaleDeviceAddr = nullptr;
        void* groupListDeviceAddr = nullptr;
        void* outputDeviceAddr = nullptr;
        void* outputScaleDeviceAddr = nullptr;

        aclTensor* x = nullptr;
        aclTensorList* weight = nullptr;
        aclTensorList* weightScale = nullptr;
        aclTensor* xScale = nullptr;
        aclTensor* groupList = nullptr;
        aclTensor* output = nullptr;
        aclTensor* outputScale = nullptr;

        std::vector<int8_t> xHostData(M * K, 0);
        std::vector<int8_t> weightHostData(E * N * K, 0);
        std::vector<float> weightScaleHostData(E * N, 0);
        std::vector<float> xScaleHostData(M, 0);
        std::vector<int64_t> groupListHostData(E, 0);
        std::vector<int8_t> outputHostData(M * N / 2, 0);
        std::vector<float> outputScaleHostData(M, 0);

        // åˆ›å»ºx aclTensor
        ret = CreateAclTensor(xHostData, xShape, &xDeviceAddr, aclDataType::ACL_INT8, aclFormat::ACL_FORMAT_ND, &x);
        CHECK_RET(ret == ACL_SUCCESS, return ret);
        // åˆ›å»ºweight aclTensorList
        ret = CreateAclTensorList(weightHostData, weightShape, weightDeviceAddr, aclDataType::ACL_INT8, aclFormat::ACL_FORMAT_FRACTAL_NZ, &weight);
        CHECK_RET(ret == ACL_SUCCESS, return ret);
        // åˆ›å»ºweightScale aclTensorList
        ret = CreateAclTensorList(weightScaleHostData, weightScaleShape, weightScaleDeviceAddr, aclDataType::ACL_FLOAT,  aclFormat::ACL_FORMAT_ND, &    weightScale);
        CHECK_RET(ret == ACL_SUCCESS, return ret);
        // åˆ›å»ºxScale aclTensor
        ret = CreateAclTensor(xScaleHostData, xScaleShape, &xScaleDeviceAddr, aclDataType::ACL_FLOAT, aclFormat::ACL_FORMAT_ND, &xScale);
        CHECK_RET(ret == ACL_SUCCESS, return ret);
        // åˆ›å»ºgroupList aclTensor
        ret = CreateAclTensor(groupListHostData, groupListShape, &groupListDeviceAddr, aclDataType::ACL_INT64, aclFormat::ACL_FORMAT_ND, &groupList);
        CHECK_RET(ret == ACL_SUCCESS, return ret);
        // åˆ›å»ºoutput aclTensor
        ret = CreateAclTensor(outputHostData, outputShape, &outputDeviceAddr, aclDataType::ACL_INT8, aclFormat::ACL_FORMAT_ND, &output);
        CHECK_RET(ret == ACL_SUCCESS, return ret);
        // åˆ›å»ºoutputScale aclTensor
        ret = CreateAclTensor(outputScaleHostData, outputScaleShape, &outputScaleDeviceAddr, aclDataType::ACL_FLOAT, aclFormat::ACL_FORMAT_ND, &    outputScale);
        CHECK_RET(ret == ACL_SUCCESS, return ret);

        // æ–°å¢V2å‚æ•°
        aclTensorList* weightAssistMatrix = nullptr;
        aclTensor* bias = nullptr;
        aclTensor* smoothScale = nullptr;
        int64_t dequantMode = 0;
        int64_t dequantDtype = 28;
        int64_t quantMode = 0;
        int64_t quantDtype = 28;
        int64_t groupListType = 0;

        std::vector<int64_t> tuningConfigData = {};
        aclIntArray* tuningConfig = aclCreateIntArray(tuningConfigData.data(), 1);

        uint64_t workspaceSize = 0;
        aclOpExecutor* executor;

        // 3. è°ƒç”¨CANNç®—å­åº“API
        // è°ƒç”¨aclnnGroupedMatmulSwigluQuantWeightNzV2ç¬¬ä¸€æ®µæ¥å£
        ret = aclnnGroupedMatmulSwigluQuantWeightNzV2GetWorkspaceSize(
            x, weight, weightScale, weightAssistMatrix, bias, xScale, smoothScale, groupList, dequantMode, dequantDtype,
            quantMode, groupListType, tuningConfig, output, outputScale, &workspaceSize, &executor);
        CHECK_RET(ret == ACL_SUCCESS, 
        LOG_PRINT("aclnnGroupedMatmulSwigluQuantWeightNzV2GetWorkspaceSize failed. ERROR: %d\n", ret); return ret);
        // æ ¹æ®ç¬¬ä¸€æ®µæ¥å£è®¡ç®—å‡ºçš„workspaceSizeç”³è¯·deviceå†…å­˜
        void* workspaceAddr = nullptr;
        if (workspaceSize > 0) {
        ret = aclrtMalloc(&workspaceAddr, workspaceSize, ACL_MEM_MALLOC_HUGE_FIRST);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("allocate workspace failed. ERROR: %d\n", ret); return ret);
        }
        // è°ƒç”¨aclnnGroupedMatmulSwigluQuantWeightNzV2ç¬¬äºŒæ®µæ¥å£
        ret = aclnnGroupedMatmulSwigluQuantWeightNzV2(workspaceAddr, workspaceSize, executor, stream);
        CHECK_RET(ret == ACL_SUCCESS, 
        LOG_PRINT("aclnnGroupedMatmulSwigluQuantWeightNzV2 failed. ERROR: %d\n", ret); return ret);

        // 4. ï¼ˆå›ºå®šå†™æ³•ï¼‰åŒæ­¥ç­‰å¾…ä»»åŠ¡æ‰§è¡Œç»“æŸ
        ret = aclrtSynchronizeStream(stream);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSynchronizeStream failed. ERROR: %d\n", ret); return ret);

        // 5. è·å–è¾“å‡ºçš„å€¼ï¼Œå°†Deviceä¾§å†…å­˜ä¸Šçš„ç»“æœæ‹·è´è‡³Hostä¾§ï¼Œéœ€è¦æ ¹æ®å…·ä½“APIçš„æ¥å£å®šä¹‰ä¿®æ”¹
        auto size = 10;
        std::vector<int8_t> out1Data(size, 0);
        ret = aclrtMemcpy(out1Data.data(), out1Data.size() * sizeof(out1Data[0]), outputDeviceAddr,
                            size * sizeof(out1Data[0]), ACL_MEMCPY_DEVICE_TO_HOST);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("copy result from device to host failed. ERROR: %d\n", ret); return ret);
        for (int64_t j = 0; j < size; j++) {
            LOG_PRINT("result[%ld] is: %d\n", j, out1Data[j]);
        }
        std::vector<float> out2Data(size, 0);
        ret = aclrtMemcpy(out2Data.data(), out2Data.size() * sizeof(out2Data[0]), outputScaleDeviceAddr,
                            size * sizeof(out2Data[0]), ACL_MEMCPY_DEVICE_TO_HOST);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("copy result from device to host failed. ERROR: %d\n", ret); return ret);
        for (int64_t j = 0; j < size; j++) {
            LOG_PRINT("result[%ld] is: %f\n", j, out2Data[j]);
        }
        // 6. é‡Šæ”¾aclTensorã€aclTensorListå’ŒaclScalarï¼Œéœ€è¦æ ¹æ®å…·ä½“APIçš„æ¥å£å®šä¹‰ä¿®æ”¹
        aclDestroyTensor(x);
        aclDestroyTensorList(weight);
        aclDestroyTensorList(weightScale);
        aclDestroyTensor(xScale);
        aclDestroyTensor(groupList);
        aclDestroyTensor(output);
        aclDestroyTensor(outputScale);

        aclDestroyIntArray(tuningConfig);

        // 7. é‡Šæ”¾deviceèµ„æºï¼Œéœ€è¦æ ¹æ®å…·ä½“APIçš„æ¥å£å®šä¹‰ä¿®æ”¹
        aclrtFree(xDeviceAddr);
        for (int64_t i = 0; i < 1; i++) {
            aclrtFree(weightDeviceAddr[i]);
            aclrtFree(weightScaleDeviceAddr[i]);
        }
        aclrtFree(weightDeviceAddr);
        aclrtFree(weightScaleDeviceAddr);
        aclrtFree(xScaleDeviceAddr);
        aclrtFree(groupListDeviceAddr);
        aclrtFree(outputDeviceAddr);
        aclrtFree(outputScaleDeviceAddr);
        if (workspaceSize > 0) {
            aclrtFree(workspaceAddr);
        }
        aclrtDestroyStream(stream);
        aclrtResetDevice(deviceId);
        aclFinalize();
        return 0;
    }
    ```

  - <term>æ˜‡è…¾910_95 AIå¤„ç†å™¨</term>ï¼š
    ```cpp
    #include <iostream>
    #include <memory>
    #include <vector>

    #include "acl/acl.h"
    #include "aclnnop/aclnn_grouped_matmul_swiglu_quant_v2.h"

    #define CHECK_RET(cond, return_expr) \
        do {                               \
          if (!(cond)) {                   \
            return_expr;                   \
          }                                \
        } while (0)

    #define CHECK_FREE_RET(cond, return_expr) \
        do {                                  \
            if (!(cond)) {                    \
                Finalize(deviceId, stream);   \
                return_expr;                  \
            }                                 \
        } while (0)

    #define LOG_PRINT(message, ...)     \
        do {                              \
          printf(message, ##__VA_ARGS__); \
        } while (0)

    int64_t GetShapeSize(const std::vector<int64_t>& shape) {
        int64_t shapeSize = 1;
        for (auto i : shape) {
            shapeSize *= i;
        }
        return shapeSize;
    }

    int Init(int32_t deviceId, aclrtStream* stream) {
        // å›ºå®šå†™æ³•ï¼Œèµ„æºåˆå§‹åŒ–
        auto ret = aclInit(nullptr);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclInit failed. ERROR: %d\n", ret); return ret);
        ret = aclrtSetDevice(deviceId);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSetDevice failed. ERROR: %d\n", ret); return ret);
        ret = aclrtCreateStream(stream);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtCreateStream failed. ERROR: %d\n", ret); return ret);
        return 0;
    }

    template <typename T>
    int CreateAclTensor(const std::vector<T>& hostData, const std::vector<int64_t>& shape, void** deviceAddr,
                            aclDataType dataType, aclFormat FormatType, aclTensor** tensor) {
        auto size = GetShapeSize(shape) * sizeof(T);
        // è°ƒç”¨aclrtMallocç”³è¯·Deviceä¾§å†…å­˜
        auto ret = aclrtMalloc(deviceAddr, size, ACL_MEM_MALLOC_HUGE_FIRST);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMalloc failed. ERROR: %d\n", ret); return ret);

        // è°ƒç”¨aclrtMemcpyå°†Hostä¾§æ•°æ®æ‹·è´åˆ°Deviceä¾§å†…å­˜ä¸Š
        ret = aclrtMemcpy(*deviceAddr, size, hostData.data(), size, ACL_MEMCPY_HOST_TO_DEVICE);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtMemcpy failed. ERROR: %d\n", ret); return ret);

        // è®¡ç®—è¿ç»­tensorçš„strides
        std::vector<int64_t> strides(shape.size(), 1);
        for (int64_t i = shape.size() - 2; i >= 0; i--) {
            strides[i] = shape[i + 1] * strides[i + 1];
        }

        // è°ƒç”¨aclCreateTensoræ¥å£åˆ›å»ºaclTensor
        *tensor = aclCreateTensor(shape.data(), shape.size(), dataType, strides.data(), 0, FormatType,
                                  shape.data(), shape.size(), *deviceAddr);
        return 0;
    }

    template <typename T>
    int CreateAclTensorList(const std::vector<std::vector<T>>& hostData, const std::vector<std::vector<int64_t>>& shapes, 
                            void** deviceAddr, aclDataType dataType, aclTensorList** tensor) {
        int size = shapes.size();
        aclTensor* tensors[size];
        for (int i = 0; i < size; i++) {
            int ret = CreateAclTensor<T>(hostData[i], shapes[i], deviceAddr + i, dataType, ACL_FORMAT_ND, tensors + i);
            CHECK_RET(ret == ACL_SUCCESS, return ret);
        }
        *tensor = aclCreateTensorList(tensors, size);
        return ACL_SUCCESS;
    }

    template <typename T1, typename T2>
    auto CeilDiv(T1 a, T2 b) -> T1
    {
        if (b == 0) {
            return a;
        }
        return (a + b - 1) / b;
    }

    void Finalize(int32_t deviceId, aclrtStream stream)
    {
        aclrtDestroyStream(stream);
        aclrtResetDevice(deviceId);
        aclFinalize();
    }

    int aclnnGroupedMatmulSwigluQuantV2Test(int32_t deviceId, aclrtStream& stream) 
    {
        auto ret = Init(deviceId, &stream);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("Init acl failed. ERROR: %d\n", ret); return ret);

        // 2. æ„é€ è¾“å…¥ä¸è¾“å‡ºï¼Œéœ€è¦æ ¹æ®APIçš„æ¥å£è‡ªå®šä¹‰æ„é€ 
        int64_t E = 8;
        int64_t M = 2048;
        int64_t N = 4096;
        int64_t K = 7168;

        std::vector<int64_t> xShape = {M, K};
        std::vector<int64_t> weightShape = {E, K, N};
        std::vector<int64_t> weightScaleShape = {E, CeilDiv(K, 64), N, 2};
        std::vector<int64_t> xScaleShape = {M, CeilDiv(K, 64), 2};
        std::vector<int64_t> groupListShape = {E};
        std::vector<int64_t> outputShape = {M, N / 2};
        std::vector<int64_t> outputScaleShape = {M, CeilDiv((N / 2), 64), 2};

        void* xDeviceAddr = nullptr;
        void* weightDeviceAddr = nullptr;
        void* weightScaleDeviceAddr = nullptr;
        void* xScaleDeviceAddr = nullptr;
        void* groupListDeviceAddr = nullptr;
        void* outputDeviceAddr = nullptr;
        void* outputScaleDeviceAddr = nullptr;

        aclTensor* x = nullptr;
        aclTensorList* weight = nullptr;
        aclTensorList* weightScale = nullptr;
        aclTensor* xScale = nullptr;
        aclTensor* groupList = nullptr;
        aclTensor* output = nullptr;
        aclTensor* outputScale = nullptr;
        aclTensorList* weightAssistMatri = nullptr;
        aclTensorList* smoothScale = nullptr;

        std::vector<int8_t> xHostData(M * K, 1);
        std::vector<int8_t> weightHostData(E * N * K, 1);
        std::vector<int8_t> weightScaleHostData(E * CeilDiv(K, 64) * N * 2, 1);
        std::vector<int8_t> xScaleHostData(M * CeilDiv(K, 64) * 2, 1);
        std::vector<int64_t> groupListHostData(E, 1);
        std::vector<int8_t> outputHostData(M * N / 2, 1);
        std::vector<int8_t> outputScaleHostData(M * CeilDiv((N / 2), 64) * 2, 1);
        std::vector<int64_t> tuningConfigData = {1};
        aclIntArray *tuningConfig = aclCreateIntArray(tuningConfigData.data(), 1);
        
        int64_t quantMode = 2;
        int64_t dequantMode = 2;
        int64_t dequantDtype = 0;
        int64_t groupListType = 1;

        // åˆ›å»ºx aclTensor
        std::vector<unsigned char> xHostDataUnsigned(xHostData.begin(), xHostData.end());
        ret = CreateAclTensor<uint8_t>(xHostDataUnsigned, xShape, &xDeviceAddr, aclDataType::ACL_FLOAT8_E5M2, aclFormat::ACL_FORMAT_ND, &x);
        std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor*)> xTensorPtr(x, aclDestroyTensor);
        std::unique_ptr<void, aclError (*)(void*)> xDeviceAddrPtr(xDeviceAddr, aclrtFree);
        CHECK_RET(ret == ACL_SUCCESS, return ret);

        // åˆ›å»ºweight aclTensorList
        std::vector<std::vector<int8_t>> weightHostDataList = {weightHostData};
        std::vector<std::vector<int64_t>> weightShapeList = {weightShape};
        ret = CreateAclTensorList<int8_t>(weightHostDataList, weightShapeList, &weightDeviceAddr, aclDataType::ACL_FLOAT8_E5M2, &weight);
        std::unique_ptr<aclTensorList, aclnnStatus (*)(const aclTensorList*)> weightTensorListPtr(weight, aclDestroyTensorList);
        std::unique_ptr<void, aclError (*)(void*)> weightDeviceAddrPtr(weightDeviceAddr, aclrtFree);
        CHECK_RET(ret == ACL_SUCCESS, return ret);
        
        // åˆ›å»ºweightScale aclTensorList
        std::vector<std::vector<int8_t>> weightScaleHostDataList = {weightScaleHostData};
        std::vector<std::vector<int64_t>> weightScaleShapeList = {weightScaleShape};
        ret = CreateAclTensorList<int8_t>(weightScaleHostDataList, weightScaleShapeList, &weightScaleDeviceAddr, aclDataType::ACL_FLOAT8_E8M0, &weightScale);
        std::unique_ptr<aclTensorList, aclnnStatus (*)(const aclTensorList*)> weightScaleTensorListPtr(weightScale, aclDestroyTensorList);
        std::unique_ptr<void, aclError (*)(void*)> weightScaleDeviceAddrPtr(weightScaleDeviceAddr, aclrtFree);
        CHECK_RET(ret == ACL_SUCCESS, return ret);

        // åˆ›å»ºxScale aclTensor
        ret = CreateAclTensor<int8_t>(xScaleHostData, xScaleShape, &xScaleDeviceAddr, aclDataType::ACL_FLOAT8_E8M0, aclFormat::ACL_FORMAT_ND, &xScale);
        std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor*)> xScaleTensorPtr(xScale, aclDestroyTensor);
        std::unique_ptr<void, aclError (*)(void*)> xScaleDeviceAddrPtr(xScaleDeviceAddr, aclrtFree);
        CHECK_RET(ret == ACL_SUCCESS, return ret);

        // åˆ›å»ºgroup_list aclTensor
        ret = CreateAclTensor<int64_t>(groupListHostData, groupListShape, &groupListDeviceAddr, aclDataType::ACL_INT64, aclFormat::ACL_FORMAT_ND, &groupList);
        std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor*)> groupListTensorPtr(groupList, aclDestroyTensor);
        std::unique_ptr<void, aclError (*)(void*)> groupListDeviceAddrPtr(groupListDeviceAddr, aclrtFree);
        CHECK_RET(ret == ACL_SUCCESS, return ret);

        // åˆ›å»ºy aclTensor
        ret = CreateAclTensor<int8_t>(outputHostData, outputShape, &outputDeviceAddr, aclDataType::ACL_FLOAT8_E5M2, aclFormat::ACL_FORMAT_ND, &output);
        std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor*)> outputTensorPtr(output, aclDestroyTensor);
        std::unique_ptr<void, aclError (*)(void*)> outputDeviceAddrPtr(outputDeviceAddr, aclrtFree);
        CHECK_RET(ret == ACL_SUCCESS, return ret);

        // åˆ›å»ºyScale aclTensor
        ret = CreateAclTensor<int8_t>(outputScaleHostData, outputScaleShape, &outputScaleDeviceAddr, aclDataType::ACL_FLOAT8_E8M0, aclFormat::ACL_FORMAT_ND, &outputScale);
        std::unique_ptr<aclTensor, aclnnStatus (*)(const aclTensor*)> outputScaleTensorPtr(outputScale, aclDestroyTensor);
        std::unique_ptr<void, aclError (*)(void*)> outputScaleDeviceAddrPtr(outputScaleDeviceAddr, aclrtFree);
        CHECK_RET(ret == ACL_SUCCESS, return ret);

        uint64_t workspaceSize = 0;
        aclOpExecutor* executor;
        void* workspaceAddr = nullptr;

        // 3. è°ƒç”¨CANNç®—å­åº“API
        // è°ƒç”¨aclnnGroupedMatmulSwigluQuantV2ç¬¬ä¸€æ®µæ¥å£
        ret = aclnnGroupedMatmulSwigluQuantV2GetWorkspaceSize(x, weight, weightScale, nullptr, nullptr, xScale, nullptr, groupList, 
                                                            dequantMode, dequantDtype, quantMode, groupListType, nullptr, output, outputScale, &workspaceSize, &executor);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnGroupedMatmulSwigluQuantV2GetWorkspaceSize failed. ERROR: %d\n", ret); return ret);
        // æ ¹æ®ç¬¬ä¸€æ®µæ¥å£è®¡ç®—å‡ºçš„workspaceSizeç”³è¯·deviceå†…å­˜
        if (workspaceSize > 0) {
            ret = aclrtMalloc(&workspaceAddr, workspaceSize, ACL_MEM_MALLOC_HUGE_FIRST);
            CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("allocate workspace failed. ERROR: %d\n", ret); return ret);
        }
        // è°ƒç”¨aclnnGroupedMatmulSwigluQuantV2ç¬¬äºŒæ®µæ¥å£
        ret = aclnnGroupedMatmulSwigluQuantV2(workspaceAddr, workspaceSize, executor, stream);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnGroupedMatmulSwigluQuantV2 failed. ERROR: %d\n", ret); return ret);

        // 4. ï¼ˆå›ºå®šå†™æ³•ï¼‰åŒæ­¥ç­‰å¾…ä»»åŠ¡æ‰§è¡Œç»“æŸ
        ret = aclrtSynchronizeStream(stream);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("aclrtSynchronizeStream failed. ERROR: %d\n", ret); return ret);

        // 5. è·å–è¾“å‡ºçš„å€¼ï¼Œå°†Deviceä¾§å†…å­˜ä¸Šçš„ç»“æœæ‹·è´è‡³Hostä¾§ï¼Œéœ€è¦æ ¹æ®å…·ä½“APIçš„æ¥å£å®šä¹‰ä¿®æ”¹
        auto size = GetShapeSize(outputShape);
        std::vector<int8_t> outputData(size, 0);
        ret = aclrtMemcpy(outputData.data(), size * sizeof(outputData[0]), outputDeviceAddr,
                          size * sizeof(outputData[0]), ACL_MEMCPY_DEVICE_TO_HOST);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("copy outputData from device to host failed. ERROR: %d\n", ret); return ret);
        for (int64_t j = 0; j < size; j++) {
            LOG_PRINT("result[%ld] is: %d\n", j, outputData[j]);
        }

        size = GetShapeSize(outputScaleShape);
        std::vector<int8_t> outputScaleData(size, 0);
        ret = aclrtMemcpy(outputScaleData.data(), size * sizeof(outputScaleData[0]), outputScaleDeviceAddr,
                          size * sizeof(outputScaleData[0]), ACL_MEMCPY_DEVICE_TO_HOST);
        CHECK_RET(ret == ACL_SUCCESS, LOG_PRINT("copy outputScaleData from device to host failed. ERROR: %d\n", ret); return ret);
        for (int64_t j = 0; j < size; j++) {
            LOG_PRINT("result[%ld] is: %d\n", j, outputScaleData[j]);
        }
        return ACL_SUCCESS;
    }

    int main()
    {
        // ï¼ˆå›ºå®šå†™æ³•ï¼‰device/streamåˆå§‹åŒ–ï¼Œå‚è€ƒAscendCLå¯¹å¤–æ¥å£åˆ—è¡¨
        // æ ¹æ®è‡ªå·±çš„å®é™…deviceå¡«å†™deviceId
        int32_t deviceId = 0;
        aclrtStream stream;
        auto ret = aclnnGroupedMatmulSwigluQuantV2Test(deviceId, stream);
        CHECK_FREE_RET(ret == ACL_SUCCESS, LOG_PRINT("aclnnGroupedMatmulSwigluQuantV2Test failed. ERROR: %d\n", ret); return ret);

        Finalize(deviceId, stream);
        return 0;
    }
    ```